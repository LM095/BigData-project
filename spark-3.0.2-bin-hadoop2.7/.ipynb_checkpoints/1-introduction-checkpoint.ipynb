{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Python and Jupyter Notebooks {-}\n",
    "\n",
    "**Python** is a high-level, dynamic, object-oriented programming language. It is a general purpose language, which is designed to be easy to use and easy to read.\n",
    "\n",
    "**Jupyter Notebooks** are a web-based interactive computational environment for creating Python notebooks. A notebook is a JSON document containing an ordered list of input/output cells which can contain code, text, mathematics, plots and rich media. Notebooks make data analysis easier to perform, understand and reproduce. All laboratories in this course are prepared as Notebooks. As you can see, in this Notebook, we can put text, images, hyperlinks, source code... The Notebooks can be converted to a number of open standard output formats (HTML, HTML presentation slides, LaTeX, PDF, ReStructuredText, Markdown, Python) through `File` -> `Download As` in the web interface. In addition, Jupyter manages the notebooks' versions through a `checkpoint` mechanism. You can create checkpoint anytime via `File -> Save and Checkpoint`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals of the Laboratory\n",
    "In this introductory laboratory, we expect students to:\n",
    "\n",
    "1. Acquire basic knowledge about Python and Matplotlib\n",
    "2. Gain familiarity with Juypter Notebooks\n",
    "3. Gain familiarity with the PySpark API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Python, NumPy, and Matplotlib\n",
    "\n",
    "This section aims to help students gain a basic understanding of the python programming language and some of its libraries, including `NumPy` or `Matplotlib`. \n",
    "\n",
    "When working with a small dataset (one that can comfortably fit into a single machine), NumPy and Matplotlib, together with Python are valid alternatives to other popular tools such as R and Matlab. Using such libraries allows to inherit from the simple and clear Python syntax, achieve very good performance, enjoy superior memory management,  error handling, and good package management \\[[1](http://ajminich.com/2013/06/22/9-reasons-to-switch-from-matlab-to-python/)\\].\n",
    "\n",
    "\n",
    "## 1.1. Python syntax\n",
    "\n",
    "(This section is for students who did not program in Python before. If you're familiar with Python, please move to the next section: 1.2. Numpy)\n",
    "\n",
    "When working with Python, the code seems to be simpler than (many) other languages. In this laboratory, we compare the Python syntax to that of Java - another very common language.\n",
    "\n",
    "```java\n",
    "// java syntax\n",
    "int i = 10;\n",
    "string s = \"advanced machine learning\";\n",
    "System.out.println(i);\n",
    "System.out.println(s);\n",
    "// you must not forget the semicolon at the end of each sentence\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python syntax\n",
    "i = 10\n",
    "s = \"advanced machine learning\"\n",
    "print(i)\n",
    "print(s)\n",
    "# forget about the obligation of commas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indentation & If-else syntax\n",
    "In python, we don't use `{` and `}` to define blocks of codes: instead, we use indentation to do that. **The code within the same block must have the same indentation**. For example, in java, we write:\n",
    "```java\n",
    "string language = \"Python\";\n",
    "\n",
    "// the block is surrounded by { and }\n",
    "// the condition is in ( and )\n",
    "if (language == \"Python\") {\n",
    "    int x = 1;\n",
    "    x += 10;\n",
    "       int y = 5; // a wrong indentation isn't problem\n",
    "    y = x + y;\n",
    "    System.out.println(x + y);\n",
    "    \n",
    "    // a statement is broken into two line\n",
    "    x = y\n",
    "        + y;\n",
    "    \n",
    "    // do some stuffs\n",
    "}\n",
    "else if (language == \"Java\") {\n",
    "    // another block\n",
    "}\n",
    "else {\n",
    "    // another block\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    }
   ],
   "source": [
    "language = \"Python\"\n",
    "if language == \"Python\":\n",
    "    x = 10\n",
    "    x += 10\n",
    "    y = 5 # all statements in the same block must have the same indentation\n",
    "    y = (\n",
    "        x + y\n",
    "    ) # statements can be on multiple lines, using ( )\n",
    "    print (x \n",
    "           + y)\n",
    "    \n",
    "    # statements can also be split on multiple lines by using \\ at the END of each line\n",
    "    x = y \\\n",
    "        + y\n",
    "    \n",
    "    # do some other stuffs\n",
    "elif language == \"Java\":\n",
    "    # another block\n",
    "    pass\n",
    "else:\n",
    "    # another block\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ternary conditional operator\n",
    "In python, we often see ternary conditional operator, which is used to assign a value to a variable based on some condition. For example, in java, we write:\n",
    "\n",
    "```java\n",
    "int x = 10;\n",
    "// if x > 10, assign y = 5, otherwise, y = 15\n",
    "int y = (x > 10) ? 5 : 15;\n",
    "\n",
    "int z;\n",
    "if (x > 10)\n",
    "    z = 5; // it's not necessary to have { } when the block has only one statement\n",
    "else\n",
    "    z = 15;\n",
    "```\n",
    "\n",
    "Of course, although we can easily write these lines of code in an `if else` block to get the same result, people prefer ternary conditional operator because of simplicity.\n",
    "\n",
    "In python, we write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 10\n",
    "# a very natural way\n",
    "y = 5 if x > 10 else 15\n",
    "print(y)\n",
    "\n",
    "# another way\n",
    "y = x > 10 and 5 or 15\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lists and For loops\n",
    "Another syntax that we should revisit is the `for loop`. In java, we can write:\n",
    "\n",
    "```java\n",
    "// init an array with 10 integer numbers\n",
    "int[] array = new int[]{1, 2, 3, 4, 5, 6, 7, 8, 9, 10};\n",
    "for (int i = 0; i < array.length; i++){\n",
    "    // print the i-th element of array\n",
    "    System.out.println(array[i]);\n",
    "}\n",
    "```\n",
    "\n",
    "In Python, instead of using an index to help indicating an element, we can access the element directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "# Python has no built-in array data structure\n",
    "# instead, it uses \"list\" which is much more general \n",
    "# and can be used as a multidimensional array quite easily.\n",
    "for element in array:\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the code is very clean. If you need the index of each element, here's what you should do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (index, element) in enumerate(array):\n",
    "    print(index, element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually, Python has no built-in array data structure. It uses the `list` data structure, which is much more general and can be used as a multidimensional array quite easily. In addition, elements in a list can be retrieved in a very concise way. For example, we create a 2d-array with 4 rows. Each row has 3 elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-dimentions array with 4 rows, 3 columns\n",
    "twod_array = [[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]]\n",
    "for index, row in enumerate(twod_array):\n",
    "    print(\"row \", index, \":\", row)\n",
    "\n",
    "# print row 1 until row 3\n",
    "print(\"row 1 until row 3: \", twod_array[1:3])\n",
    "\n",
    "# all rows from row 2\n",
    "print(\"all rows from row 2: \", twod_array[2:])\n",
    "\n",
    "# all rows until row 2\n",
    "print(\"all rows until row 2:\", twod_array[:2])\n",
    "\n",
    "# all rows from the beginning with step of 2. \n",
    "print(\"all rows from the beginning with step of 2:\", twod_array[::2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionaries\n",
    "Another useful data structure in Python is a `dictionary`, which we use to store (key, value) pairs. Here's some example usage of dictionaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'key1': 'value1', 'key2': 'value2'}  # Create a new dictionary with some data\n",
    "print(d['key1'])       # Get an entry from a dictionary; prints \"value1\"\n",
    "print('key1' in d)     # Check if a dictionary has a given key; prints \"True\"\n",
    "d['key3'] = 'value3'    # Set an entry in a dictionary\n",
    "print(d['key3'])      # Prints \"value3\"\n",
    "# print(d['key9'])  # KeyError: 'key9' not a key of d\n",
    "print(d.get('key9', 'custom_default_value'))  # Get an element with a default; prints \"custom_default_value\"\n",
    "print(d.get('key3', 'custom_default_value'))    # Get an element with a default; prints \"value3\"\n",
    "del d['key3']        # Remove an element from a dictionary\n",
    "print(d.get('key3', 'custom_default_value')) # \"fish\" is no longer a key; prints \"custom_default_value\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions\n",
    "In Python, we can define a function by using keyword `def`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square(x):\n",
    "    return x*x\n",
    "\n",
    "print(square(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can apply a function to each element of a list/array by using `lambda` function. For example, we want to square elements in a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "# apply function \"square\" on each element of \"array\"\n",
    "print(list(map(lambda x: square(x), array)))\n",
    "\n",
    "# or using a for loop, and a list comprehension\n",
    "print([square(x) for x in array])\n",
    "\n",
    "print(\"orignal array:\", array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two above syntaxes are used very often. \n",
    "\n",
    "If you are not familiar with **list comprehensions**, follow this [link](http://python-3-patterns-idioms-test.readthedocs.io/en/latest/Comprehensions.html]).\n",
    "\n",
    "We can also put a function `B` inside a function `A` (that is, we can have nested functions). In that case, function `B` is only accessed inside function `A` (the scope that it's declared). For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only the prime number in array\n",
    "# and square them\n",
    "def filterAndSquarePrime(arr):\n",
    "    \n",
    "    # a very simple function to check a number is prime or not\n",
    "    def checkPrime(number):\n",
    "        for i in range(2, int(number/2)):\n",
    "            if number % i == 0:\n",
    "                return False\n",
    "        return True\n",
    "    \n",
    "    primeNumbers = filter(lambda x: checkPrime(x), arr)\n",
    "    return map(lambda x: square(x), primeNumbers)\n",
    "\n",
    "# we can not access checkPrime from here\n",
    "# checkPrime(5)\n",
    "\n",
    "result = filterAndSquarePrime(array)\n",
    "list(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing modules, functions\n",
    "Modules in Python are packages of code. Putting code into modules helps increasing the reusability and maintainability.\n",
    "The modules can be nested.\n",
    "To import a module, we simple use syntax: `import <module_name>`. Once it is imported, we can use any functions, classes inside it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import module 'math' to uses functions for calculating\n",
    "import math\n",
    "\n",
    "# print the square root of 16\n",
    "print(math.sqrt(16))\n",
    "\n",
    "# we can create alias when import a module\n",
    "import numpy as np\n",
    "\n",
    "print(np.sqrt(16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, you only need to import some functions inside a module to avoid loading the whole module into memory. To do that, we can use syntax: `from <module> import <function>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only import function 'sin' in package 'math'\n",
    "from math import sin\n",
    "\n",
    "# use the function\n",
    "print(sin(60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's quite enough for Python. Now, let's practice a little bit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "#### Question 1.1\n",
    "<div class=\"alert alert-info\">\n",
    "Write a function `checkSquareNumber` to check if a integer number is a square number or not. For example, 16 and 9 are square numbers. 15 isn't square number.\n",
    "Requirements:\n",
    "\n",
    "- Input: an integer number\n",
    "\n",
    "- Output: `True` or `False`\n",
    "\n",
    "HINT: If the square root of a number is an integer number, it is a square number.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import math\n",
    "\n",
    "def checkSquareNumber(x):\n",
    "    # calculate the square root of x\n",
    "    # return True if square root is integer, \n",
    "    # otherwise, return False\n",
    "    return ...\n",
    "\n",
    "print(checkSquareNumber(16))\n",
    "print(checkSquareNumber(250))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1.2\n",
    "<div class=\"alert alert-info\">\n",
    "A list `list_numbers` which contains the numbers from 1 to 9999 can be constructed from: \n",
    "\n",
    "```python\n",
    "list_numbers = list(range(0, 10000))\n",
    "```\n",
    "\n",
    "Extract the square numbers in `list_numbers` using function `checkSquareNumber` from question 1.1. How many elements in the extracted list ?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "list_numbers = ...\n",
    "square_numbers = # try to use the filter method\n",
    "print(square_numbers)\n",
    "print(len(square_numbers))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1.3\n",
    "<div class=\"alert alert-info\">\n",
    "Using array slicing, select the elements of the list square_numbers, whose index is from 5 to 20 (zero-based index).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "print(square_numbers[...])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will take a quick look on Numpy - a powerful module of Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Numpy\n",
    "Numpy is the core library for scientific computing in Python. It provides a high-performance multidimensional array object, and tools for working with these arrays.\n",
    "### 1.2.1. Array\n",
    "A numpy array is a grid of values, all of **the same type**, and is indexed by a tuple of nonnegative integers. Thanks to the same type property, Numpy has the benefits of [locality of reference](https://en.wikipedia.org/wiki/Locality_of_reference). Besides, many other Numpy operations are implemented in C, avoiding the general cost of loops in Python, pointer indirection and per-element dynamic type checking. So, the speed of Numpy is often faster than using built-in datastructure of Python. When working with massive data with computationally expensive tasks, you should consider to use Numpy. \n",
    "\n",
    "The number of dimensions is the `rank` of the array; the `shape` of an array is a tuple of integers giving the size of the array along each dimension.\n",
    "\n",
    "We can initialize numpy arrays from nested Python lists, and access elements using square brackets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create a rank 1 array\n",
    "rank1_array = np.array([1, 2, 3])\n",
    "print(\"type of rank1_array:\", type(rank1_array))\n",
    "print(\"shape of rank1_array:\", rank1_array.shape)\n",
    "print(\"elements in rank1_array:\", rank1_array[0], rank1_array[1], rank1_array[2])\n",
    "\n",
    "# Create a rank 2 array\n",
    "rank2_array = np.array([[1,2,3],[4,5,6]])\n",
    "print(\"shape of rank2_array:\", rank2_array.shape)\n",
    "print(rank2_array[0, 0], rank2_array[0, 1], rank2_array[1, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2. Array slicing\n",
    "Similar to Python lists, numpy arrays can be sliced. The different thing is that you must specify a slice for each dimension of the array because arrays may be multidimensional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_array = np.array([[1,2,3,4], [5,6,7,8], [9,10,11,12]])\n",
    "\n",
    "# Use slicing to pull out the subarray consisting of the first 2 rows\n",
    "# and columns 1 and 2\n",
    "b = m_array[:2, 1:3]\n",
    "print(b)\n",
    "\n",
    "# we can only use this syntax with numpy array, not python list\n",
    "print(\"value at row 0, column 1:\", m_array[0, 1])\n",
    "\n",
    "# Rank 1 view of the second row of m_array  \n",
    "print(\"the second row of m_array:\", m_array[1, :])\n",
    "\n",
    "# print element at position (0,2) and (1,3)\n",
    "print(m_array[[0,1], [2,3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3. Boolean array indexing\n",
    "We can use boolean array indexing to check whether each element in the array satisfies a condition or use it to do filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_array = np.array([[1,2,3,4], [5,6,7,8], [9,10,11,12]])\n",
    "\n",
    "# Find the elements of a that are bigger than 2\n",
    "# this returns a numpy array of Booleans of the same\n",
    "# shape as m_array, where each value of bool_idx tells\n",
    "# whether that element of a is > 3 or not\n",
    "bool_idx = (m_array > 3)\n",
    "print(bool_idx , \"\\n\")\n",
    "\n",
    "# We use boolean array indexing to construct a rank 1 array\n",
    "# consisting of the elements of a corresponding to the True values\n",
    "# of bool_idx\n",
    "print(m_array[bool_idx], \"\\n\")\n",
    "\n",
    "# We can combine two statements\n",
    "print(m_array[m_array > 3], \"\\n\")\n",
    "\n",
    "# select elements with multiple conditions\n",
    "print(m_array[(m_array > 3) & (m_array % 2 == 0)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.4. Datatypes\n",
    "Remember that the elements in a numpy array have the same type. When constructing arrays, Numpy tries to guess a datatype when you create an array However, we can specify the datatype explicitly via an optional argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let Numpy guess the datatype\n",
    "x1 = np.array([1, 2])\n",
    "print(x1.dtype)\n",
    "\n",
    "# force the datatype be float64\n",
    "x2 = np.array([1, 2], dtype=np.float64)\n",
    "print(x2.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.5. Array math\n",
    "Similar to Matlab or R, in Numpy, basic mathematical functions operate elementwise on arrays, and are available both as operator overloads and as functions in the numpy module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1,2],[3,4]], dtype=np.float64)\n",
    "y = np.array([[5,6],[7,8]], dtype=np.float64)\n",
    "# mathematical function is used as operator\n",
    "print(\"x + y =\", x + y, \"\\n\")\n",
    "\n",
    "# mathematical function is used as function\n",
    "print(\"np.add(x, y)=\", np.add(x, y), \"\\n\")\n",
    "\n",
    "# Unlike MATLAB, * is elementwise multiplication\n",
    "# not matrix multiplication\n",
    "print(\"x * y =\", x * y , \"\\n\")\n",
    "print(\"np.multiply(x, y)=\", np.multiply(x, y), \"\\n\")\n",
    "print(\"x*2=\", x*2, \"\\n\")\n",
    "\n",
    "# to multiply two matrices, we use dot function\n",
    "print(\"x.dot(y)=\", x.dot(y), \"\\n\")\n",
    "print(\"np.dot(x, y)=\", np.dot(x, y), \"\\n\")\n",
    "\n",
    "# Elementwise square root\n",
    "print(\"np.sqrt(x)=\", np.sqrt(x), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that unlike MATLAB, `*` is elementwise multiplication, not matrix multiplication. We instead use the `dot` function to compute inner products of vectors, to multiply a vector by a matrix, and to multiply matrices. In what follows, we work on a few more examples to reiterate the concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare two vectors\n",
    "v = np.array([9,10])\n",
    "w = np.array([11, 12])\n",
    "\n",
    "# Inner product of vectors\n",
    "print(\"v.dot(w)=\", v.dot(w))\n",
    "print(\"np.dot(v, w)=\", np.dot(v, w))\n",
    "\n",
    "# Matrix / vector product\n",
    "print(\"x.dot(v)=\", x.dot(v))\n",
    "print(\"np.dot(x, v)=\", np.dot(x, v))\n",
    "\n",
    "# Matrix / matrix product\n",
    "print(\"x.dot(y)=\", x.dot(y))\n",
    "print(\"np.dot(x, y)=\", np.dot(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, we can do other aggregation computations on arrays such as `sum`, `nansum`, or `T`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1,2], [3,4]])\n",
    "\n",
    "# Compute sum of all elements\n",
    "print(np.sum(x))\n",
    "\n",
    "# Compute sum of each column\n",
    "print(np.sum(x, axis=0))\n",
    "\n",
    "# Compute sum of each row\n",
    "print(np.sum(x, axis=1))\n",
    "\n",
    "# transpose the matrix\n",
    "print(x.T)\n",
    "\n",
    "# Note that taking the transpose of a rank 1 array does nothing:\n",
    "v = np.array([1,2,3])\n",
    "print(v.T)  # Prints \"[1 2 3]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "Given a 2D array:\n",
    "\n",
    "```\n",
    " 1  2  3  4\n",
    " 5  6  7  8 \n",
    " 9 10 11 12\n",
    "13 14 15 16\n",
    "```\n",
    "\n",
    "\n",
    "#### Question 2.1\n",
    "<div class=\"alert alert-info\">\n",
    "Print the all odd numbers in this array using `Boolean array indexing`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "array_numbers = np.array([\n",
    "        [1, 2, 3, 4],\n",
    "        [5, 6, 7, 8],\n",
    "        [9, 10, 11, 12],\n",
    "        [13, 14, 15, 16]\n",
    "    ])\n",
    "\n",
    "print(...)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2.2\n",
    "<div class=\"alert alert-info\">\n",
    "Extract the second row and the third column in this array using `array slicing`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "print(array_numbers[...])\n",
    "print(array_numbers[...])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2.3\n",
    "<div class=\"alert alert-info\">\n",
    "Calculate the sum of diagonal elements.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "sum = 0\n",
    "for i in range(0, ...):\n",
    "    sum += array_numbers...\n",
    "    \n",
    "print(sum)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2.4\n",
    "<div class=\"alert alert-info\">\n",
    "Print elementwise multiplication of the first row and the last row using numpy's functions.\n",
    "\n",
    "Print the inner product of these two rows.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "print(...)\n",
    "print(...)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Matplotlib\n",
    "\n",
    "As its name indicates, Matplotlib is a plotting library. It provides both a very quick way to visualize data from Python and publication-quality figures in many formats. The most important function in matplotlib is `plot`, which allows you to plot 2D data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot([1,2,3,4])\n",
    "plt.ylabel('custom y label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we provide a single list or array to the `plot()` command, matplotlib assumes it is a sequence of y values, and automatically generates the x values for us. Since python ranges start with 0, the default x vector has the same length as y but starts with 0. Hence the x data are [0,1,2,3].\n",
    "\n",
    "In the next example, we plot figure with both x and y data. Besides, we want to draw dashed lines instead of the solid in default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([1, 2, 3, 4], [1, 4, 9, 16], 'r--')\n",
    "plt.show()\n",
    "\n",
    "plt.bar([1, 2, 3, 4], [1, 4, 9, 16], align='center')\n",
    "# labels of each column bar\n",
    "x_labels = [\"Type 1\", \"Type 2\", \"Type 3\", \"Type 4\"]\n",
    "# assign labels to the plot\n",
    "plt.xticks([1, 2, 3, 4], x_labels)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to merge two figures into a single one, subplot is the best way to do that. For example, we want to put two figures in a stack vertically, we should define a grid of plots with 2 rows and 1 column. Then, in each row, a single figure is plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a subplot grid that has height 2 and width 1,\n",
    "# and set the first such subplot as active.\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot([1, 2, 3, 4], [1, 4, 9, 16], 'r--')\n",
    "\n",
    "# Set the second subplot as active, and make the second plot.\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.bar([1, 2, 3, 4], [1, 4, 9, 16])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more examples, please visit the [homepage](http://matplotlib.org/1.5.1/examples/index.html) of Matplotlib."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Question 3\n",
    "Given a list of numbers from 0 to 9999.\n",
    "\n",
    "\n",
    "#### Question 3.1\n",
    "<div class=\"alert alert-info\">\n",
    "Calculate the histogram of numbers divisible by 3, 7, 11 in the list respectively.\n",
    "\n",
    "( Or in other words, how many numbers divisible by 3, 7, 11 in the list respectively ?)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "arr = np.array(...)\n",
    "divisors = [3, 7, 11]\n",
    "histogram = list(...)\n",
    "print(histogram)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3.2\n",
    "<div class=\"alert alert-info\">\n",
    "Plot the histogram in a line chart.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# simple line chart\n",
    "plt.plot(histogram)\n",
    "x_indexes = ...\n",
    "x_names = ...\n",
    "plt.xticks(x_indexes, x_names)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "To plot the histogram ia a bar chart try\n",
    "```python\n",
    "plt.bar( x_indexes, histogram, align='center')\n",
    "plt.xticks(x_indexes, x_names)\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. PySpark\n",
    "\n",
    "Spark is an alternative framework to Hadoop MapReduce, designed to make it easier and quicker to build and run distributed data manipulation algorithms. Spark comes with a library for machine learning (MLLib) and graph algorithms, and also supports real-time streaming and SQL syntax, via Spark Streaming and SparkSQL, respectively. Spark exposes the Spark programming model to Java, Scala, or Python. In Python, we use the PySpark API to interact with Spark.\n",
    "\n",
    "As discussed in the CLOUDS lectures, every Spark application has a Spark driver. It is the program that declares the transformations and actions on RDDs of data and submits such requests to the cluster manager. Actually, the driver is the program that creates the `SparkContext`, connecting to a given cluster manager such as  Spark Master, YARN or others. The executors run user code, run computations and can cache data for your application. The `SparkContext` will create a job that is broken into stages. The stages are broken into tasks which are scheduled by the SparkContext on an executor.\n",
    "\n",
    "When starting PySpark with command `pyspark` or using a well configured notebook (such as this one), `SparkContext` is created automatically in variable `sc`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://localhost:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PySpark uses PySpark RDDs which  are just RDDs of Python objects: like Python lists, they can store objects with mixed types (actually all the objects are instances of `PyObject`).\n",
    "\n",
    "When PySpark is started, it also starts a JVM, which is accessible through a socket. PySpark uses `Py4J` to handle this communication. The JVM works as the actual Spark driver, and loads a `JavaSparkContext` that communicates with the Spark executors across the cluster. Python API calls to the Spark Context object are then **translated into Java API calls** to the JavaSparkContext. For example, the implementation of PySpark's `sc.textFile()` dispatches a call to the `.textFile` method of the `JavaSparkContext`, which ultimately communicates with the Spark executor JVMs to load the text data from HDFS. \n",
    "\n",
    "![](http://i.imgur.com/YlI8AqEl.png)\n",
    "\n",
    "The Spark executors on the cluster start a Python interpreter for each core, with which they communicate data through a pipe when they need to execute user-code. A Python RDD in the local PySpark client corresponds to a `PythonRDD` object in the local JVM. The data associated with the RDD actually lives in the Spark JVMs as Java objects. For example, running `sc.textFile()` in the Python interpreter will call the `JavaSparkContexts` `textFile` method, which loads the data as Java String objects in the cluster.\n",
    "\n",
    "\n",
    "When an API call is made on the `PythonRDD`, any associated code (e.g., Python lambda function) **is serialized and distributed to the executors**. The data is then converted from Java objects to a Python-compatible representation (e.g., pickle objects) and streamed to executor-associated Python interpreters through a pipe. Any necessary Python processing is executed in the interpreter, and the resulting data is stored back as an RDD (as pickle objects by default) in the JVMs. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is read easily by using functions of Spark Context. For example, to read a text file and count the number of lines, we can write:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each line is stored as an element in 'input_file' - a PythonRDD.\n",
    "input_file = sc.textFile(\"datasets/short_stories_I.txt\")\n",
    "num_lines = input_file.count()\n",
    "print(\"The number of lines in the input file is:\", num_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.  Apache Spark Web UI to inspect jobs, tasks and many more metrics\n",
    "\n",
    "The usual workflow include reading and wrting on a distributed filesystem, such as **HDFS**, or from any other storage (e.g., a NoSQL database). \n",
    "In the following examples, we always consider files saved in the local disk, since we focus mainly on processing, rather than the entire workflow. In a real cluster, files should be read from a distributed filestytem/storage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with the Apache Spark Web UI\n",
    "The Apache Spark Web UI can be used to dissect the life of a job execution.\n",
    "Every time you launch a pySpark notebook, there will be a different Spark Web UI for the jobs launched in that notebook. The port numbering starts from 4040 and it adds 1 at every new notebook.\n",
    "\n",
    "It is possible to know the address of the Spark Web UI with the following command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://localhost:4042'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.uiWebUrl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(the above result is specific to my execution, you should run the command)\n",
    "\n",
    "When you run a job, such as the cell with the simple \"line counting\", you will see a single item in the job list, whose job name corresponds to the name of the **Action** that fired the job, that is, the ```count``` action. At this level, you only see a coarse job summary: its submission time, its duration, and so on.\n",
    "\n",
    "* Click on the job description. You will land on a page with a great deal of details about your job, starting with its stages (remember, jobs are made of stages, that are in turn made of tasks);\n",
    "* Expand the sections about the **Event Timeline** and the **DAG visualization**;\n",
    "* Next, click on the job stage with the same name as the **Action** ```count``` we specified in our code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "<div class=\"alert alert-info\">\n",
    "Using the Apache Spark Web UI, as explained above, answer the following questions:\n",
    "</div>\n",
    "\n",
    "* How many tasks were launched?\n",
    "* What is the duration of each task?\n",
    "* Hown many input bytes where processed by each task? How does this relate to the input file size?\n",
    "* How many workers in total does your cluster have? How many workers were involved in your \"line count\" job?\n",
    "* Given that we know how many HDFS blocks compose our input file (from Question 3.1), explain the number of tasks your job is broken into.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Wordcount example\n",
    "In the example below, we are interested in the top-10 words in terms of frequency of occurrence. To do so, we use a small text file as an input, and we wish to plot the term frequency of such top-10 words using Matplotlib.\n",
    "\n",
    "First, using the method `textFile` from the SparkContext `sc`, we create a RDD of strings. Each string in the RDD is representative for a line in the text file. In a loose way, we can think the first RDD is a RDD of lines. \n",
    "\n",
    "Because we work on the scope of words, we have to transform **a line** of the current RDD into **multiple words**, each word is an object of the new RDD. This is done by using `flatMap` function. \n",
    "\n",
    "Then, a `map` function transforms **each word** in the RDD into **a single** tuple with 2 components: the word itself and the count of 1. As you might have guessed, this is a PairRDD, where each object is a key-value pair. \n",
    "\n",
    "We can take advantage of function `reduceByKey` to sum all frequencies of the same word. Now, each element in the RDD is in the form of: (word, total_frequency). To sort the words by frequency of occurrence, we can use many approaches. One of the simplest approach is swap each tuple such that the frequency becomes the key, and use the `sortByKey` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = (\n",
    "            # read the text file\n",
    "            sc.textFile(\"datasets/short_stories_I.txt\").repartition(4)\n",
    "            \n",
    "            # construct words from lines\n",
    "            .flatMap(lambda line: line.split())\n",
    "            \n",
    "            # map each word to (word, 1)\n",
    "            .map(lambda x: (x, 1))\n",
    "    \n",
    "            # reduce by key: accumulate sum the freq of the same word\n",
    "            .reduceByKey(lambda freq1, freq2: freq1 + freq2)\n",
    "            \n",
    "            # swap (word, freq) to (freq, word)\n",
    "            .map(lambda x: (x[1], x[0]))\n",
    "    \n",
    "            # sort result by key DESC\n",
    "            .sortByKey(False)\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "<div class=\"alert alert-info\">\n",
    "Using both the terminal and the Apache Spark Web UI, as explained above, answer the following questions:\n",
    "</div>\n",
    "\n",
    "* What is the size of the input file?\n",
    "* How many blocks the input file is broken into? What is the block size?\n",
    "* How many tasks execute in parallel?\n",
    "* How many jobs were launched upon the execution of the code above? Why (note that there are no actions!)?\n",
    "* What does a **\"skipped\"** stage mean?\n",
    "* What is the number of shuffled bytes? How does this compare to the number of input bytes?\n",
    "* Do you think Spark is doing a good job in balancing the load across the workers? What can go wrong with load balancing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the top-10 words are collected and sent back to the driver by using function `take`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 10 words:\n",
    "top10 = words.take(10)\n",
    "print(top10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The action `collect` gathers all elements of the RDD (that reside on multiple machines) to the driver (which is running in a single machine), and cast it as a list.\n",
    "\n",
    "**ATTENTION** collecting an RDD in the driver can be problematic: indeed, an RDD can be very big in size (this is why they are distributed across several machines in the first place!) and thus it could deplete the RAM available in the machine running the driver!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect results from executors to the driver\n",
    "# results = words.collect()\n",
    "# If you want to have a look at the results, don't print them all, for otherwise the notebook size will be too big"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that there are two kinds of functions in Spark: **transformations** and **actions**. All functions `map`, `flatMap`, `reduceByKey`, `sortByKey` are transformation functions. They are not executed right away when called. Indeed, Spark is lazily evaluated, so nothing gets executed unless the driver invokes actions such as `count`, `take`, `collect`...\n",
    "\n",
    "RDD transformations allow us to create dependencies between RDDs. Each RDD in the lineage chain (string of dependencies) has a function for calculating its data and has a pointer (dependency) to its parent RDD. Every time we use an RDD, dependencies are computed again from the beginning, which can be costly. Fortunately, we can use the function `cache` to instruct Spark to checkpoint in RAM (but eventually also on disk) a particular RDD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now use the previous results from the execution of our simple Spark word count job, to plot word frequency information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEACAYAAACpoOGTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfjkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3d7a1e8f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# extract the frequencies from the result\n",
    "frequencies = [x[0] for x in top10]\n",
    "\n",
    "# plot the frequencies\n",
    "plt.plot(frequencies)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "This notebook is inspired from:\n",
    "\n",
    "- [Python Numpy tutorial](http://cs231n.github.io/python-numpy-tutorial/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
