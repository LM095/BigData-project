{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will learn how to perform simple data analytics tasks. We will start with basic operations on a simple file, then we use the data from the airline stats.\n",
    "\n",
    "We will explore the different Spark operations, i.e., **trasformations** and **actions**, through a set of questions.\n",
    "Recall that *trasformations* are lazily evaluated, they get execute when we call an *action*.\n",
    "\n",
    "Examples of *transformations* are:\n",
    " - Narrow: map, flatMap, filter, sample, union, ...\n",
    " - Wide: reduceByKey, groupByKey, join, repartition, ...\n",
    "\n",
    "Examples of *actions* are:\n",
    " - count, collect, take, top, saveAsTextFile, ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Basic operations with Spark\n",
    "In the following, we provide some useful operations in Spark. For a complete list, see the following reference\n",
    "\n",
    "https://spark.apache.org/docs/latest/rdd-programming-guide.html\n",
    "\n",
    "## 1.1. Loading the Dataset\n",
    "\n",
    "The RDD we analyze can be derived either from a collection of data or HDFS (most common case).\n",
    "\n",
    "Parallelized collections are created by calling `SparkContext`’s `parallelize` method on an existing iterable or collection in your driver program. The elements of the collection are copied to form a distributed dataset that can be operated on in parallel. For example, here is how to create a parallelized collection holding the numbers 1 to 5:\n",
    "\n",
    "```python\n",
    "data = list(range(1,1000))\n",
    "distData = sc.parallelize(data)\n",
    "```\n",
    "\n",
    "It is possible to specify the number of partitions to cut the dataset into (e.g., if we want to split into 5 partitions, we use `sc.parallelize(data, 5)`). Typically you want 2-4 partitions for each CPU in your cluster. Normally, Spark tries to set the number of partitions automatically based on your cluster. \n",
    "\n",
    "Data from HDFS (or any other storage) can be loaded into an RDD\n",
    "Spark can create RDD from any storage source supported by Hadoop, including your local file system, HDFS, HBase, etc. Spark supports text files, SequenceFiles, and any other Hadoop InputFormat.\n",
    "\n",
    "Text file RDDs can be created using SparkContext’s textFile method. This method takes an URI for the file (either a local path on the machine, or a hdfs://, s3a://, etc URI) and reads it as a **collection of lines**. \n",
    "\n",
    "```python\n",
    "input_file = sc.textFile(\"datasets/short_stories_I.txt\")\n",
    "```\n",
    "\n",
    "Finally, you can save the results of a computation (most likely, an RDD) with:\n",
    "\n",
    "```python\n",
    "rddToBeSaved.saveAsTextFile(\"filename_with_path\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Persistence\n",
    "\n",
    "If we are going to use an RDD multiple times, then we can explicitly tell Spark to keep it in RAM with `persist()`\n",
    "```python\n",
    "input_file.persist()\n",
    "```\n",
    "When you persist an RDD, each node stores any partitions of it that it computes in memory and reuses them in other actions on that dataset (or datasets derived from it). This allows future actions to be much faster.\n",
    "\n",
    "In addition, each persisted RDD can be stored using a different *storage level*, allowing you, for example, to persist the dataset on disk and in memory. For a detailed discussion on RDD Persistence, please see\n",
    "\n",
    "https://spark.apache.org/docs/latest/rdd-programming-guide.html#rdd-persistence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Operations: Actions\n",
    "\n",
    "### Actions for seeing the output\n",
    "Let's start with some basic **actions**. We have already seen `saveAsTextFile()` which trigger the computation and the writing to a file. We can instead see the results at the driver program with `collect()`, which returns the elements of the dataset as an array\n",
    "\n",
    "```python\n",
    "input_file.collect()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### count()\n",
    "\n",
    "Actions that trigger the counting of the number of elements in an RDD\n",
    "```python\n",
    "input_file.count()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### take(n) and takeOrdered(n, [ordering])\n",
    "\n",
    "`take(n)` returns an array with the first `n` elements of the dataset\n",
    "```python\n",
    "input_file.take(5)\n",
    "```\n",
    "`takeOrdered(n, [ordering])` returns the first `n` elements of the RDD using either their *natural order* or a custom comparator (note that now we use the RDD `distData`)\n",
    "```python\n",
    "distData.takeOrdered(5)\n",
    "distData.takeOrdered(5, lambda x: -x)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Operations: Transformations\n",
    "\n",
    "### map(func)\n",
    "It returns a new RDD formed by passing *each element* of the source RDD through a function `func`.\n",
    "\n",
    "We consider a simple function, and we apply it to the  RDD `distData`\n",
    "```python\n",
    "def square(x): \n",
    "    return x*x\n",
    "\n",
    "distDataSquared = distData.map(square)\n",
    "distDataSquared.take(5)\n",
    "```\n",
    "Another example: we would like to know the number of words in each line of a file \n",
    "```python\n",
    "def wordsPerLine(s):\n",
    "    words = s.split(\" \")\n",
    "    return len(words)\n",
    "\n",
    "nWords = input_file.map(wordsPerLine)\n",
    "nWords.take(5)\n",
    "```\n",
    "There is no need to explicit a different RDD at every operation (if we do not need them for other transformations), they can be combined together\n",
    "```python\n",
    "input_file.map(wordsPerLine).take(5)\n",
    "```\n",
    "Finally, for simple functions, we can use inline functions (lambda functions)\n",
    "```python\n",
    "distData.map(lambda x: x*x).take(5)\n",
    "input_file.map(lambda line: len(line.split(\" \"))).take(5)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 1, 1, 15, 12, 3, 1, 13, 15, 8, 1, 15, 8, 1, 3, 1, 9, 1, 2, 1, 12, 1, 5, 1, 13, 1, 15, 8, 1, 17, 5, 1, 3, 1, 15, 14, 16, 1, 1, 4, 1, 16, 10, 1, 12, 14, 14, 16, 16, 12, 12, 15, 11, 14, 15, 14, 13, 1, 1, 10, 1, 16, 4, 1, 14, 15, 13, 14, 15, 13, 12, 11, 1, 1, 12, 15, 12, 11, 13, 13, 11, 15, 9, 1, 15, 14, 13, 14, 1, 1, 4, 1, 7, 1, 7, 1, 12, 4, 1, 7]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def wordsPerLine(s):\n",
    "    words = s.split(\" \")\n",
    "    return len(words)\n",
    "\n",
    "input_file = sc.textFile(\"dataset/short_stories_I.txt\")\n",
    "nWords = input_file.map(wordsPerLine)\n",
    "inputNew = input_file.map(wordsPerLine).take(100)\n",
    "print(inputNew)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### flatMap(func)\n",
    "Similar to `map`, but the output is *flattened*. An example will make the difference clear.\n",
    "```python\n",
    "wordsWithMap = input_file.map(lambda line: line.split(\" \"))\n",
    "wordsWithFlatMap = input_file.flatMap(lambda line: line.split(\" \"))\n",
    "print(wordsWithMap.take(5))\n",
    "print(wordsWithFlatMap.take(15))\n",
    "```\n",
    "Since the `split` method produces a list, then the RDD created with `map` will be a list of lists. Instead, with `flatMap` the lists are merged in a single output list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['AN', 'HONEST', 'THIEF'], [''], [''], ['One', 'morning,', 'just', 'as', 'I', 'was', 'about', 'to', 'set', 'off', 'to', 'my', 'office,', 'Agrafena,', 'my'], ['cook,', 'washerwoman', 'and', 'housekeeper,', 'came', 'in', 'to', 'me', 'and,', 'to', 'my', 'surprise,'], ['entered', 'into', 'conversation.'], [''], ['She', 'had', 'always', 'been', 'such', 'a', 'silent,', 'simple', 'creature', 'that,', 'except', 'her', 'daily'], ['inquiry', 'about', 'dinner,', 'she', 'had', 'not', 'uttered', 'a', 'word', 'for', 'the', 'last', 'six', 'years.', 'I,'], ['at', 'least,', 'had', 'heard', 'nothing', 'else', 'from', 'her.'], [''], ['\"Here', 'I', 'have', 'come', 'in', 'to', 'have', 'a', 'word', 'with', 'you,', 'sir,\"', 'she', 'began', 'abruptly;'], ['\"you', 'really', 'ought', 'to', 'let', 'the', 'little', 'room.\"'], [''], ['\"Which', 'little', 'room?\"'], [''], ['\"Why,', 'the', 'one', 'next', 'the', 'kitchen,', 'to', 'be', 'sure.\"'], [''], ['\"What', 'for?\"'], [''], ['\"What', 'for?', 'Why', 'because', 'folks', 'do', 'take', 'in', 'lodgers,', 'to', 'be', 'sure.\"'], [''], ['\"But', 'who', 'would', 'take', 'it?\"'], [''], ['\"Who', 'would', 'take', 'it?', 'Why,', 'a', 'lodger', 'would', 'take', 'it,', 'to', 'be', 'sure.\"'], [''], ['\"But,', 'my', 'good', 'woman,', 'one', 'could', 'not', 'put', 'a', 'bedstead', 'in', 'it;', 'there', \"wouldn't\", 'be'], ['room', 'to', 'move!', 'Who', 'could', 'live', 'in', 'it?\"'], [''], ['\"Who', 'wants', 'to', 'live', 'there!', 'As', 'long', 'as', 'he', 'has', 'a', 'place', 'to', 'sleep', 'in.', 'Why,', 'he'], ['would', 'live', 'in', 'the', 'window.\"'], [''], ['\"In', 'what', 'window?\"'], [''], ['\"In', 'what', 'window!', 'As', 'though', 'you', \"didn't\", 'know!', 'The', 'one', 'in', 'the', 'passage,', 'to', 'be'], ['sure.', 'He', 'would', 'sit', 'there,', 'sewing', 'or', 'doing', 'anything', 'else.', 'Maybe', 'he', 'would', 'sit'], ['on', 'a', 'chair,', 'too.', \"He's\", 'got', 'a', 'chair;', 'and', 'he', 'has', 'a', 'table,', 'too;', \"he's\", 'got'], ['everything.\"'], [''], ['\"Who', 'is', \"'he'\", 'then?\"']]\n",
      "\n",
      "['AN', 'HONEST', 'THIEF', '', '', 'One', 'morning,', 'just', 'as', 'I', 'was', 'about', 'to', 'set', 'off', 'to', 'my', 'office,', 'Agrafena,', 'my', 'cook,', 'washerwoman', 'and', 'housekeeper,', 'came', 'in', 'to', 'me', 'and,', 'to', 'my', 'surprise,', 'entered', 'into', 'conversation.', '', 'She', 'had', 'always', 'been']\n"
     ]
    }
   ],
   "source": [
    "wordsWithMap = input_file.map(lambda line: line.split(\" \"))\n",
    "wordsWithFlatMap = input_file.flatMap(lambda line: line.split(\" \"))\n",
    "print(wordsWithMap.take(40))\n",
    "print()\n",
    "print(wordsWithFlatMap.take(40))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filter(func)\n",
    "It returns a new RDD formed by selecting those elements of the source on which `func` returns true. Therefore, `func` should return a boolean value.\n",
    "\n",
    "```python\n",
    "input_file.filter(lambda line: len(line.split(\" \"))>5).take(10)\n",
    "```\n",
    "\n",
    "Note that this could not be with `map`, since with `map` each element maps to the element in the new RDD, and it cannot be omitted. For instance, try this\n",
    "```python\n",
    "input_file.map(lambda line: line if len(line.split(\" \"))>5 else None).take(10)\n",
    "```\n",
    "\n",
    "We can also use the `filter` to filter out empty lines from the file we are reading. We can use either `.filter(lambda x: x)` or, using the builtin function `bool`, `.filter(bool)`\n",
    "```python\n",
    "wordsWithMap = input_file.filter(bool).map(lambda line: line.split(\" \"))\n",
    "wordsWithFlatMap = input_file.filter(bool).flatMap(lambda line: line.split(\" \"))\n",
    "print(wordsWithMap.take(5))\n",
    "print(wordsWithFlatMap.take(15))\n",
    "```\n",
    "\n",
    "Note that it is always better to filter before applying `map` (but the tool usually knows that, and it does it when translating the job into a set of tasks)\n",
    "Note also that all the operations can be concatenated, as in the following example:\n",
    "```python\n",
    "lowerCaseWords = input_file.filter(bool) \\\n",
    "                    .flatMap(lambda line: line.split(\" \")) \\\n",
    "                    .map(lambda w: w.lower())\n",
    "print(lowerCaseWords.take(15))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['an', 'honest', 'thief', 'one', 'morning,', 'just', 'as', 'i', 'was', 'about', 'to', 'set', 'off', 'to', 'my']\n"
     ]
    }
   ],
   "source": [
    "#print(input_file.filter(lambda line: len(line.split(\" \"))>5).take(10))\n",
    "#print('\\n \\n')\n",
    "#print(input_file.map(lambda line: line if len(line.split(\" \"))>5 else None).take(10))\n",
    "\n",
    "lowerCaseWords = input_file.filter(bool) \\\n",
    "                    .flatMap(lambda line: line.split(\" \")) \\\n",
    "                    .map(lambda w: w.lower())\n",
    "print(lowerCaseWords.take(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with key-value pairs\n",
    "\n",
    "Representing the data using a key-value is design pattern that is widely adopted to solve many problems, expecially when data need to be reorganized is different ways. For instace, it is common to group and aggregate elements by a key.\n",
    "\n",
    "For this reason, Spark has a few special operations that are only available on RDDs of key-value pairs. A key-value element in a RDD is simply a tuple with two objects (e.g., a string and an int). \n",
    "\n",
    "It is simple to create a tuple from simple elements: just apply the `map` transformation.\n",
    "```python\n",
    "wordsList = input_file.filter(bool) \\\n",
    "            .flatMap(lambda line: line.split(\" \"))\\ \n",
    "            .map(lambda w: w.lower())\n",
    "wordsKeyValue = wordsList.map(lambda w: (w,1))\n",
    "print(wordsKeyValue.take(10))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('an', 1), ('honest', 1), ('thief', 1), ('one', 1), ('morning,', 1), ('just', 1), ('as', 1), ('i', 1), ('was', 1), ('about', 1)]\n"
     ]
    }
   ],
   "source": [
    "wordsList = input_file.filter(bool).flatMap(lambda line: line.split(\" \")).map(lambda w: w.lower())\n",
    "wordsKeyValue = wordsList.map(lambda w: (w,1))\n",
    "print(wordsKeyValue.take(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### groupByKey()\n",
    "\n",
    "When called on a dataset of (K, V) pairs, returns a dataset of (K, Iterable<V>) pairs.\n",
    "*Note*: If you are grouping in order to perform an aggregation (such as a sum or average) over each key, using `reduceByKey` will yield much better performance.\n",
    "\n",
    "Continuing the example above (except for the first line, the other are required to print the results):\n",
    "```python\n",
    "wordsGrouped = wordsKeyValue.groupByKey()\n",
    "results = wordsGrouped.take(10)\n",
    "for item in results:\n",
    "    print(item[0], \" > \", end='')\n",
    "    for elem in item[1]:\n",
    "        print(elem, \",\", end='')\n",
    "    print()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "an  > 1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,\n",
      "thief  > 1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,\n",
      "just  > 1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,\n",
      "as  > 1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,\n",
      "i  > 1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,\n",
      "was  > 1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,\n",
      "set  > 1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,\n",
      "agrafena,  > 1 ,1 ,\n",
      "washerwoman  > 1 ,\n",
      "housekeeper,  > 1 ,\n"
     ]
    }
   ],
   "source": [
    "wordsGrouped = wordsKeyValue.groupByKey()\n",
    "results = wordsGrouped.take(10)\n",
    "for item in results:\n",
    "    print(item[0], \" > \", end='')\n",
    "    for elem in item[1]:\n",
    "        print(elem, \",\", end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reduceByKey(func)\n",
    "\n",
    "When called on a dataset of (K, V) pairs, returns a dataset of (K, V) pairs where the values for each key are aggregated using the given reduce function `func`, which must be of type (V,V) => V.\n",
    "\n",
    "Continuing the example above:\n",
    "```python\n",
    "wordsReduceBy = wordsKeyValue.reduceByKey(lambda a,b: a+b)\n",
    "print(wordsReduceBy.take(10))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('an', 16), ('thief', 8), ('just', 13), ('as', 44), ('i', 238), ('was', 110), ('set', 8), ('agrafena,', 2), ('washerwoman', 1), ('housekeeper,', 1)]\n"
     ]
    }
   ],
   "source": [
    "wordsReduceBy = wordsKeyValue.reduceByKey(lambda a,b: a+b)\n",
    "print(wordsReduceBy.take(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wordcount - full example\n",
    "\n",
    "As a final example, let's see the full Wordcount problem.\n",
    "We are interested in the top-10 words in terms of number of occurrences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "words = sc.textFile(\"dataset/short_stories_I.txt\").filter(bool) \\\n",
    "            .flatMap(lambda line: line.split(\" \")) \\\n",
    "            .map(lambda w: w.lower()) \\\n",
    "            .map(lambda w: (w, 1)) \\\n",
    "            .reduceByKey(lambda v1, v2: v1 + v2) \\\n",
    "            .map(lambda x: (x[1], x[0])) \\\n",
    "            .sortByKey(False)\n",
    "top10 = words.take(10)\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# extract the frequencies from the result\n",
    "frequencies = [x[0] for x in top10]\n",
    "x_indexes = list(range(0,10))\n",
    "x_labels = [x[1] for x in top10]\n",
    "plt.xticks(x_indexes, x_labels)\n",
    "\n",
    "# plot the frequencies\n",
    "plt.plot(frequencies)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Airline Data Analysis\n",
    "\n",
    "## 2.1 Use case\n",
    "\n",
    "In this notebook, we play the role of a data scientist working in the travel industry, specifically on air transportation of passengers. We want to explore the data related to airline activities to understand passengers' behavior, as well as the properties of all flights, across several airline companies.\n",
    "\n",
    "The dataset can be found at\n",
    "http://stat-computing.org/dataexpo/2009/the-data.html\n",
    "\n",
    "It contains 29 features, that can be either categorical or numerical. For example, the ```Origin``` (source airport) is categorical: there exist no comparison operator between airport names. We can not say \"SGN is bigger than NCE\". The ```DepTime``` (departure time) feature is numerical, for which a comparison operator exists. For instance, \"flight departing before 6PM\" can be express by \"DepTime < 1800\". The structure of each line is as follows:\n",
    "\n",
    "`\n",
    "1\t Year\t1987-2008\n",
    "2\t Month\t1-12\n",
    "3\t DayofMonth\t1-31\n",
    "4\t DayOfWeek\t1 (Monday) - 7 (Sunday)\n",
    "5\t DepTime\tactual departure time (local, hhmm)\n",
    "6\t CRSDepTime\tscheduled departure time (local, hhmm)\n",
    "7\t ArrTime\tactual arrival time (local, hhmm)\n",
    "8\t CRSArrTime\tscheduled arrival time (local, hhmm)\n",
    "9\t UniqueCarrier\tunique carrier code\n",
    "10\t FlightNum\tflight number\n",
    "11\t TailNum\tplane tail number\n",
    "12\t ActualElapsedTime\tin minutes\n",
    "13\t CRSElapsedTime\tin minutes\n",
    "14\t AirTime\tin minutes\n",
    "15\t ArrDelay\tarrival delay, in minutes\n",
    "16\t DepDelay\tdeparture delay, in minutes\n",
    "17\t Origin\torigin IATA airport code\n",
    "18\t Dest\tdestination IATA airport code\n",
    "19\t Distance\tin miles\n",
    "20\t TaxiIn\ttaxi in time, in minutes\n",
    "21\t TaxiOut\ttaxi out time in minutes\n",
    "22\t Cancelled\twas the flight cancelled?\n",
    "23\t CancellationCode\treason for cancellation (A = carrier, B = weather, C = NAS, D = security)\n",
    "24\t Diverted\t1 = yes, 0 = no\n",
    "25\t CarrierDelay\tin minutes\n",
    "26\t WeatherDelay\tin minutes\n",
    "27\t NASDelay\tin minutes\n",
    "28\t SecurityDelay\tin minutes\n",
    "29\t LateAircraftDelay\tin minutes\n",
    "`\n",
    "\n",
    "There is a single CSV file per year, you may download some years and put them in a directory. Then you could work on individual years, or feed the entire directory to your jobs such that you can process all years.\n",
    "\n",
    "This is what the beginning of a file looks like:\n",
    "\n",
    "`\n",
    "Year,Month,DayofMonth,DayOfWeek,DepTime,CRSDepTime,ArrTime,CRSArrTime,UniqueCarrier,FlightNum,TailNum,ActualElapsedTime,CRSElapsedTime,AirTime,ArrDelay,DepDelay,Origin,Dest,Distance,TaxiIn,TaxiOut,Cancelled,CancellationCode,Diverted,CarrierDelay,WeatherDelay,NASDelay,SecurityDelay,LateAircraftDelay\n",
    "1994,1,7,5,858,900,954,1003,US,227,NA,56,63,NA,-9,-2,CLT,ORF,290,NA,NA,0,NA,0,NA,NA,NA,NA,NA\n",
    "1994,1,8,6,859,900,952,1003,US,227,NA,53,63,NA,-11,-1,CLT,ORF,290,NA,NA,0,NA,0,NA,NA,NA,NA,NA\n",
    "1994,1,10,1,935,900,1023,1003,US,227,NA,48,63,NA,20,35,CLT,ORF,290,NA,NA,0,NA,0,NA,NA,NA,NA,NA\n",
    "1994,1,11,2,903,900,1131,1003,US,227,NA,148,63,NA,88,3,CLT,ORF,290,NA,NA,0,NA,0,NA,NA,NA,NA,NA\n",
    "1994,1,12,3,933,900,1024,1003,US,227,NA,51,63,NA,21,33,CLT,ORF,290,NA,NA,0,NA,0,NA,NA,NA,NA,NA\n",
    "1994,1,13,4,NA,900,NA,1003,US,227,NA,NA,63,NA,NA,NA,CLT,ORF,290,NA,NA,1,NA,0,NA,NA,NA,NA,NA\n",
    "`\n",
    "\n",
    "Each file contains a header, that is useless when analyzing the data: it serves the purpose of an \"embedded schema\", to help data scientist figure out what information is available. Note that there are some features with missing values in some lines of the dataset. The missing values are marked by \"NA\". These values can cause problems when processing the data and can lead to unexpected results. Therefore, we need to remove the header and replace all \"NA\" values by empty values, such as they can be interpreted as null values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Data exploration\n",
    "\n",
    "In order to start understanding the dataset, we may answer to some basic questions:\n",
    "\n",
    " - How many unique origin airports?\n",
    " - How many unique destination airports?\n",
    " - How many carriers?\n",
    " - How many night flights do we have in our data? (\"night\" starts at 6pm)\n",
    " - How many night flights per unique carrier?\n",
    "\n",
    "Here there are some hints...\n",
    "```python\n",
    "# load the data\n",
    "rawData = sc.textFile(\"datasets/1994_sample.csv\")\n",
    "# extract header\n",
    "header = rawData.first() \n",
    "# remove the header, separate the elements for each row\n",
    "data = rawData.filter(lambda row: row != header).map(lambda row : row.split(\",\")) \n",
    "# put the data in cache\n",
    "data.persist()\n",
    "# check the output\n",
    "print(data.take(3))\n",
    "\n",
    "# unique origin airports: element 16 of each line (the .keys() may not be necessary)\n",
    "data.map(lambda x: (x[16], 1)).groupByKey().keys().count()\n",
    "\n",
    "\n",
    "# flights that start after 6pm\n",
    "data.filter(lambda x: x[4] != \"NA\" and int(x[4]) > 1800).count()\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['1994', '1', '7', '5', '858', '900', '954', '1003', 'US', '227', 'NA', '56', '63', 'NA', '-9', '-2', 'CLT', 'ORF', '290', 'NA', 'NA', '0', 'NA', '0', 'NA', 'NA', 'NA', 'NA', 'NA'], ['1994', '1', '8', '6', '859', '900', '952', '1003', 'US', '227', 'NA', '53', '63', 'NA', '-11', '-1', 'CLT', 'ORF', '290', 'NA', 'NA', '0', 'NA', '0', 'NA', 'NA', 'NA', 'NA', 'NA'], ['1994', '1', '10', '1', '935', '900', '1023', '1003', 'US', '227', 'NA', '48', '63', 'NA', '20', '35', 'CLT', 'ORF', '290', 'NA', 'NA', '0', 'NA', '0', 'NA', 'NA', 'NA', 'NA', 'NA']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1120108"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data\n",
    "rawData = sc.textFile(\"dataset/1994.csv\")\n",
    "# extract header\n",
    "header = rawData.first() \n",
    "# remove the header, separate the elements for each row\n",
    "data = rawData.filter(lambda row: row != header).map(lambda row : row.split(\",\")) \n",
    "# put the data in cache\n",
    "data.persist()\n",
    "# check the output\n",
    "print(data.take(3))\n",
    "\n",
    "# unique origin airports: element 16 of each line (the .keys() may not be necessary)\n",
    "data.map(lambda x: (x[16], 1)).groupByKey().keys().count()\n",
    "\n",
    "# flights that start after 6pm\n",
    "data.filter(lambda x: x[4] != \"NA\" and int(x[4]) > 1800).count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[8] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data\n",
    "rawData = sc.textFile(\"dataset/1994.csv\")\n",
    "# extract header\n",
    "header = rawData.first() \n",
    "# remove the header, separate the elements for each row\n",
    "data = rawData.filter(lambda row: row != header).map(lambda row : row.split(\",\")) \n",
    "# put the data in cache\n",
    "data.persist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------+------+------+------+----------+\n",
      "|    id|               title|         genre|userId|    id|rating| timestamp|\n",
      "+------+--------------------+--------------+------+------+------+----------+\n",
      "|100553|Frozen Planet (2011)|   Documentary|   105|100553|   4.5|1446572398|\n",
      "|100553|Frozen Planet (2011)|   Documentary|   318|100553|   4.5|1426353247|\n",
      "|102684|Only God Forgives...|Drama|Thriller|   249|102684|   3.5|1376654552|\n",
      "|102684|Only God Forgives...|Drama|Thriller|   380|102684|   4.0|1494709199|\n",
      "|  1090|      Platoon (1986)|     Drama|War|     1|  1090|   4.0| 964984018|\n",
      "|  1090|      Platoon (1986)|     Drama|War|    17|  1090|   4.5|1322629080|\n",
      "|  1090|      Platoon (1986)|     Drama|War|    36|  1090|   2.5|1100803399|\n",
      "|  1090|      Platoon (1986)|     Drama|War|    42|  1090|   5.0| 996212773|\n",
      "|  1090|      Platoon (1986)|     Drama|War|    51|  1090|   3.0|1230932491|\n",
      "|  1090|      Platoon (1986)|     Drama|War|    59|  1090|   4.0| 953610028|\n",
      "|  1090|      Platoon (1986)|     Drama|War|    61|  1090|   4.0|1145532596|\n",
      "|  1090|      Platoon (1986)|     Drama|War|    64|  1090|   5.0|1161528856|\n",
      "|  1090|      Platoon (1986)|     Drama|War|    66|  1090|   4.0|1093747746|\n",
      "|  1090|      Platoon (1986)|     Drama|War|    68|  1090|   2.5|1240093386|\n",
      "|  1090|      Platoon (1986)|     Drama|War|    75|  1090|   1.0|1158967824|\n",
      "|  1090|      Platoon (1986)|     Drama|War|    83|  1090|   1.5|1333842149|\n",
      "|  1090|      Platoon (1986)|     Drama|War|    84|  1090|   4.0| 858772239|\n",
      "|  1090|      Platoon (1986)|     Drama|War|   122|  1090|   5.0|1461562305|\n",
      "|  1090|      Platoon (1986)|     Drama|War|   140|  1090|   4.0|1055092338|\n",
      "|  1090|      Platoon (1986)|     Drama|War|   160|  1090|   5.0| 971112754|\n",
      "|  1090|      Platoon (1986)|     Drama|War|   182|  1090|   5.0|1054781436|\n",
      "|  1090|      Platoon (1986)|     Drama|War|   194|  1090|   4.5|1110316671|\n",
      "|  1090|      Platoon (1986)|     Drama|War|   195|  1090|   5.0| 974710189|\n",
      "|  1090|      Platoon (1986)|     Drama|War|   202|  1090|   5.0| 974912698|\n",
      "|  1090|      Platoon (1986)|     Drama|War|   204|  1090|   4.0|1327183736|\n",
      "|  1090|      Platoon (1986)|     Drama|War|   218|  1090|   3.0|1111624837|\n",
      "|  1090|      Platoon (1986)|     Drama|War|   221|  1090|   4.5|1111178155|\n",
      "|  1090|      Platoon (1986)|     Drama|War|   239|  1090|   4.5|1221159358|\n",
      "|  1090|      Platoon (1986)|     Drama|War|   244|  1090|   5.0| 975075169|\n",
      "|  1090|      Platoon (1986)|     Drama|War|   264|  1090|   3.0|1136978280|\n",
      "|  1090|      Platoon (1986)|     Drama|War|   266|  1090|   5.0| 944891645|\n",
      "|  1090|      Platoon (1986)|     Drama|War|   274|  1090|   4.0|1171943610|\n",
      "|  1090|      Platoon (1986)|     Drama|War|   287|  1090|   3.0|1110229868|\n",
      "|  1090|      Platoon (1986)|     Drama|War|   288|  1090|   4.5|1054568506|\n",
      "|  1090|      Platoon (1986)|     Drama|War|   290|  1090|   4.0| 974938908|\n",
      "|  1090|      Platoon (1986)|     Drama|War|   305|  1090|   5.0|1462397928|\n",
      "|  1090|      Platoon (1986)|     Drama|War|   312|  1090|   4.0|1043177095|\n",
      "|  1090|      Platoon (1986)|     Drama|War|   318|  1090|   4.0|1292760177|\n",
      "|  1090|      Platoon (1986)|     Drama|War|   325|  1090|   5.0|1039399280|\n",
      "|  1090|      Platoon (1986)|     Drama|War|   368|  1090|   5.0| 971273268|\n",
      "|  1090|      Platoon (1986)|     Drama|War|   372|  1090|   4.0| 874416661|\n",
      "|  1090|      Platoon (1986)|     Drama|War|   384|  1090|   4.0| 994038103|\n",
      "|  1090|      Platoon (1986)|     Drama|War|   387|  1090|   3.5|1094877353|\n",
      "|  1090|      Platoon (1986)|     Drama|War|   391|  1090|   4.0|1032389993|\n",
      "|  1090|      Platoon (1986)|     Drama|War|   414|  1090|   5.0| 961512475|\n",
      "|  1090|      Platoon (1986)|     Drama|War|   419|  1090|   4.0|1321766180|\n",
      "|  1090|      Platoon (1986)|     Drama|War|   434|  1090|   5.0|1270603951|\n",
      "|  1090|      Platoon (1986)|     Drama|War|   437|  1090|   5.0| 859721463|\n",
      "|  1090|      Platoon (1986)|     Drama|War|   448|  1090|   4.0|1019137594|\n",
      "|  1090|      Platoon (1986)|     Drama|War|   449|  1090|   3.5|1053200232|\n",
      "+------+--------------------+--------------+------+------+------+----------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "# load the data\n",
    "rawData = sc.textFile(\"dataset/movies.csv\")\n",
    "rawData2 = sc.textFile(\"dataset/ratings.csv\")\n",
    "# extract header\n",
    "header = rawData.first() \n",
    "header2 = rawData2.first() \n",
    "# remove the header, separate the elements for each row\n",
    "data = rawData.map(lambda row: next(csv.reader(row.splitlines(), skipinitialspace=True)))\n",
    "data2 = rawData2.map(lambda row: next(csv.reader(row.splitlines(), skipinitialspace=True)))\n",
    "#data = rawData.filter(lambda row: row != header).map(lambda row : row.split(\",\")) \n",
    "#data2 = rawData2.filter(lambda row: row != header2).map(lambda row : row.split(\",\")) \n",
    "# put the data in cache\n",
    "data.persist()\n",
    "data2.persist()\n",
    "prova = data.join(data2)\n",
    "tabella = spark.createDataFrame(data, ['id', 'title','genre'])\n",
    "tabella2 = spark.createDataFrame(data2, ['userId','id','rating', 'timestamp' ])\n",
    "\n",
    "\n",
    "movies = tabella.alias('movies')\n",
    "ratings = tabella2.alias('ratings')\n",
    "inner_join = movies.join(ratings, movies.id == ratings.id)\n",
    "inner_join.show(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Various queries\n",
    "In the following, there is a set of queries. Each result can be plot so that to better understand the results. For instance, the plot of the first query could be the airport code on the x-axis and the volume of traffic on the y-axis.\n",
    "\n",
    "### Question Q1: Top 20 airports by total volume of flights\n",
    "<div class=\"alert alert-info\">\n",
    "What are the busiest airports by total flight traffic. JFK will feature, but what are the others? For each airport code compute the number of inbound, outbound and all flights. Variation on the theme: compute the above by day, week, month, and over the years.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ORD', 561461), ('DFW', 516523), ('ATL', 443074), ('LAX', 306453), ('STL', 304409), ('DEN', 285526), ('PHX', 280560), ('DTW', 276272), ('PIT', 262939), ('CLT', 259712), ('MSP', 247980), ('SFO', 235478), ('EWR', 233991), ('IAH', 208591), ('LGA', 203362), ('BOS', 199696), ('LAS', 189920), ('PHL', 186897), ('DCA', 176115), ('MCO', 153720)]\n"
     ]
    }
   ],
   "source": [
    "total_vol = (data.map(lambda x: (x[16],1))\n",
    "                  .union(data.map(lambda x: (x[17],1)))\n",
    "                  .reduceByKey(lambda a,b: a+b)\n",
    "                  .takeOrdered(20, key = lambda x: -x[1]))\n",
    "print(total_vol)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('ORD', '1'), 47070), (('DFW', '1'), 43052), (('ATL', '1'), 38734), (('DEN', '1'), 25839), (('LAX', '1'), 24418), (('PHX', '1'), 23005), (('STL', '1'), 22627), (('DTW', '1'), 21641), (('PIT', '1'), 21034), (('CLT', '1'), 20046), (('MSP', '1'), 19945), (('SFO', '1'), 19245), (('EWR', '1'), 19168), (('LGA', '1'), 17179), (('BOS', '1'), 16806), (('IAH', '1'), 16267), (('PHL', '1'), 15782), (('LAS', '1'), 15078), (('DCA', '1'), 14610), (('MIA', '1'), 12281)]\n"
     ]
    }
   ],
   "source": [
    "total_vol = (data.map(lambda x: ((x[16], x[1]),1))\n",
    "                  .union(data.map(lambda x: ((x[17], x[1]), 1)))\n",
    "                  .reduceByKey(lambda a,b: a+b))\n",
    "                  \n",
    "total_fliter_jan = (total_vol.filter(lambda x: (int(x[0][1]) == 1)).takeOrdered(20, key = lambda x: -x[1]))#gennaio\n",
    "\n",
    "print(total_fliter_jan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question Q2: Carrier Popularity\n",
    "<div class=\"alert alert-info\">\n",
    "Some carriers come and go, others demonstrate regular growth. Compute the (log base 10) volume -- total flights -- over each year, by carrier. The carriers are ranked by their median volume (over the 4 year span).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question Q3: Proportion of Flights Delayed\n",
    "<div class=\"alert alert-info\">\n",
    "A flight is delayed if the delay is greater than 15 minutes. Compute the fraction of delayed flights per different time granularities (hour, day, week, month, year).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question Q4: Carrier Delays\n",
    "<div class=\"alert alert-info\">\n",
    "Is there a difference in carrier delays? Compute the proportion of delayed flights by carrier, ranked by carrier, at different time granularities (hour, day, week, month year). Again, a flight is delayed if the delay is greater than 15 minutes.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question Q5: Busy Routes\n",
    "<div class=\"alert alert-info\">\n",
    "Which routes are the busiest? A simple first approach is to create a frequency table for the unordered pair *(i,j)* where *i* and *j* are distinct airport codes.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
