{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>mid</th><th>title</th><th>year</th><th>rating</th><th>num_ratings</th></tr>\n",
       "<tr><td>1</td><td>Toy story</td><td>1995</td><td>3.7</td><td>102338</td></tr>\n",
       "<tr><td>2</td><td>Jumanji</td><td>1995</td><td>3.2</td><td>44587</td></tr>\n",
       "<tr><td>3</td><td>Grumpy Old Men</td><td>1993</td><td>3.2</td><td>10489</td></tr>\n",
       "<tr><td>4</td><td>Waiting to Exhale</td><td>1995</td><td>3.3</td><td>5666</td></tr>\n",
       "<tr><td>5</td><td>Father of the Bri...</td><td>1995</td><td>3</td><td>13761</td></tr>\n",
       "<tr><td>6</td><td>Heat</td><td>1995</td><td>3.9</td><td>42785</td></tr>\n",
       "<tr><td>7</td><td>Sabrina</td><td>1954</td><td>3.8</td><td>12812</td></tr>\n",
       "<tr><td>8</td><td>Tom and Huck</td><td>1995</td><td>2.7</td><td>2649</td></tr>\n",
       "<tr><td>9</td><td>Sudden Death</td><td>1995</td><td>2.6</td><td>3626</td></tr>\n",
       "<tr><td>10</td><td>GoldenEye</td><td>1995</td><td>3.4</td><td>28260</td></tr>\n",
       "<tr><td>11</td><td>The American Pres...</td><td>1995</td><td>3.2</td><td>8320</td></tr>\n",
       "<tr><td>12</td><td>Dracula: Dead and...</td><td>1995</td><td>2.8</td><td>10078</td></tr>\n",
       "<tr><td>13</td><td>Balto</td><td>1995</td><td>3.2</td><td>9195</td></tr>\n",
       "<tr><td>14</td><td>Nixon</td><td>1995</td><td>3.5</td><td>3256</td></tr>\n",
       "<tr><td>15</td><td>Cutthroat Island</td><td>1995</td><td>2.6</td><td>3350</td></tr>\n",
       "<tr><td>16</td><td>Casino</td><td>1995</td><td>3.9</td><td>66463</td></tr>\n",
       "<tr><td>17</td><td>Sense and Sensibi...</td><td>1995</td><td>3.8</td><td>32782</td></tr>\n",
       "<tr><td>18</td><td>Four Rooms</td><td>1995</td><td>3.5</td><td>14266</td></tr>\n",
       "<tr><td>19</td><td>Ace Ventura: When...</td><td>1995</td><td>3.2</td><td>87306</td></tr>\n",
       "<tr><td>20</td><td>Money Train</td><td>1995</td><td>2.7</td><td>5263</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+---+--------------------+----+------+-----------+\n",
       "|mid|               title|year|rating|num_ratings|\n",
       "+---+--------------------+----+------+-----------+\n",
       "|  1|           Toy story|1995|   3.7|     102338|\n",
       "|  2|             Jumanji|1995|   3.2|      44587|\n",
       "|  3|      Grumpy Old Men|1993|   3.2|      10489|\n",
       "|  4|   Waiting to Exhale|1995|   3.3|       5666|\n",
       "|  5|Father of the Bri...|1995|     3|      13761|\n",
       "|  6|                Heat|1995|   3.9|      42785|\n",
       "|  7|             Sabrina|1954|   3.8|      12812|\n",
       "|  8|        Tom and Huck|1995|   2.7|       2649|\n",
       "|  9|        Sudden Death|1995|   2.6|       3626|\n",
       "| 10|           GoldenEye|1995|   3.4|      28260|\n",
       "| 11|The American Pres...|1995|   3.2|       8320|\n",
       "| 12|Dracula: Dead and...|1995|   2.8|      10078|\n",
       "| 13|               Balto|1995|   3.2|       9195|\n",
       "| 14|               Nixon|1995|   3.5|       3256|\n",
       "| 15|    Cutthroat Island|1995|   2.6|       3350|\n",
       "| 16|              Casino|1995|   3.9|      66463|\n",
       "| 17|Sense and Sensibi...|1995|   3.8|      32782|\n",
       "| 18|          Four Rooms|1995|   3.5|      14266|\n",
       "| 19|Ace Ventura: When...|1995|   3.2|      87306|\n",
       "| 20|         Money Train|1995|   2.7|       5263|\n",
       "+---+--------------------+----+------+-----------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "from pyspark.sql.functions import min, max, col, when, lit\n",
    "from pyspark.sql.types import StructType,StructField, StringType\n",
    "from pyspark.sql import Row\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)\n",
    "\n",
    "# load the data\n",
    "movies_file = sc.textFile(\"dataset/movies.csv\")\n",
    "genres_file = sc.textFile(\"dataset/genres.csv\")\n",
    "actors_file = sc.textFile(\"dataset/actors.csv\")\n",
    "tagNames_file = sc.textFile(\"dataset/tag_names.csv\")\n",
    "tags_file = sc.textFile(\"dataset/tags.csv\")\n",
    "\n",
    "# we separate the fields for each table in csv format\n",
    "data_movies = movies_file.map(lambda row: next(csv.reader(row.splitlines(), skipinitialspace=True)))\n",
    "data_genres = genres_file.map(lambda row: next(csv.reader(row.splitlines(), skipinitialspace=True)))\n",
    "data_actors = actors_file.map(lambda row: next(csv.reader(row.splitlines(), skipinitialspace=True)))\n",
    "data_tagNames = tagNames_file.map(lambda row: next(csv.reader(row.splitlines(), skipinitialspace=True)))\n",
    "data_tags = tags_file.map(lambda row: next(csv.reader(row.splitlines(), skipinitialspace=True)))\n",
    "\n",
    "# we create the dataframe for each data generated\n",
    "table_movies = spark.createDataFrame(data_movies, ['mid', 'title','year','rating','num_ratings'])\n",
    "table_genres = spark.createDataFrame(data_genres, ['mid', 'genre'])\n",
    "table_actors = spark.createDataFrame(data_actors, ['mid', 'name', 'cast_position'])\n",
    "table_tagNames = spark.createDataFrame(data_tagNames, ['tid', 'tag'])\n",
    "table_tags = spark.createDataFrame(data_tags, ['mid', 'tid'])\n",
    "\n",
    "# create an alias for each table\n",
    "movies = table_movies.alias('movies')\n",
    "genres = table_genres.alias('genres')\n",
    "actors = table_actors.alias('actors')\n",
    "tagNames = table_tagNames.alias('tagNames')\n",
    "tags = table_tags.alias('tags')\n",
    "\n",
    "# we mantain the tables in cache\n",
    "\n",
    "genres.persist()\n",
    "actors.persist()\n",
    "tagNames.persist()\n",
    "tags.persist()\n",
    "movies.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Print all movie titles starring ‘Daniel Craig’, sorted in an ascending alphabetical order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>title</th><th>name</th></tr>\n",
       "<tr><td>A Kid in King Art...</td><td>Daniel Craig</td></tr>\n",
       "<tr><td>Archangel</td><td>Daniel Craig</td></tr>\n",
       "<tr><td>Casino Royale</td><td>Daniel Craig</td></tr>\n",
       "<tr><td>Casino Royale</td><td>Daniel Craig</td></tr>\n",
       "<tr><td>Elizabeth</td><td>Daniel Craig</td></tr>\n",
       "<tr><td>Enduring Love</td><td>Daniel Craig</td></tr>\n",
       "<tr><td>Infamous</td><td>Daniel Craig</td></tr>\n",
       "<tr><td>Lara Croft: Tomb ...</td><td>Daniel Craig</td></tr>\n",
       "<tr><td>Layer Cake</td><td>Daniel Craig</td></tr>\n",
       "<tr><td>Munich</td><td>Daniel Craig</td></tr>\n",
       "<tr><td>Quantum of Solace</td><td>Daniel Craig</td></tr>\n",
       "<tr><td>Renaissance</td><td>Daniel Craig</td></tr>\n",
       "<tr><td>Road to Perdition</td><td>Daniel Craig</td></tr>\n",
       "<tr><td>Sorstalanság</td><td>Daniel Craig</td></tr>\n",
       "<tr><td>Sylvia</td><td>Daniel Craig</td></tr>\n",
       "<tr><td>The Golden Compass</td><td>Daniel Craig</td></tr>\n",
       "<tr><td>The Invasion</td><td>Daniel Craig</td></tr>\n",
       "<tr><td>The Jacket</td><td>Daniel Craig</td></tr>\n",
       "<tr><td>The Mother</td><td>Daniel Craig</td></tr>\n",
       "<tr><td>The Mother</td><td>Daniel Craig</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+--------------------+------------+\n",
       "|               title|        name|\n",
       "+--------------------+------------+\n",
       "|A Kid in King Art...|Daniel Craig|\n",
       "|           Archangel|Daniel Craig|\n",
       "|       Casino Royale|Daniel Craig|\n",
       "|       Casino Royale|Daniel Craig|\n",
       "|           Elizabeth|Daniel Craig|\n",
       "|       Enduring Love|Daniel Craig|\n",
       "|            Infamous|Daniel Craig|\n",
       "|Lara Croft: Tomb ...|Daniel Craig|\n",
       "|          Layer Cake|Daniel Craig|\n",
       "|              Munich|Daniel Craig|\n",
       "|   Quantum of Solace|Daniel Craig|\n",
       "|         Renaissance|Daniel Craig|\n",
       "|   Road to Perdition|Daniel Craig|\n",
       "|        Sorstalanság|Daniel Craig|\n",
       "|              Sylvia|Daniel Craig|\n",
       "|  The Golden Compass|Daniel Craig|\n",
       "|        The Invasion|Daniel Craig|\n",
       "|          The Jacket|Daniel Craig|\n",
       "|          The Mother|Daniel Craig|\n",
       "|          The Mother|Daniel Craig|\n",
       "+--------------------+------------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_with_actors = movies.join(actors, movies.mid == actors.mid)\n",
    "\n",
    "movies_title_actors = movies_with_actors.select('title','name')\n",
    "movies_with_Craig = movies_title_actors.filter(movies_title_actors.name == 'Daniel Craig').sort(movies_title_actors.title.asc())\n",
    "\n",
    "# display the result: we use count to display all the rows\n",
    "#movies_with_Craig.show(movies_with_Craig.count(), truncate=False)\n",
    "movies_with_Craig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Print names of the cast of the movie ‘The Dark Knight’ in an ascending alphabetical order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>name</th></tr>\n",
       "<tr><td>Aaron Eckhart</td></tr>\n",
       "<tr><td>Adam Kalesperis</td></tr>\n",
       "<tr><td>Aidan Feore</td></tr>\n",
       "<tr><td>Andrew Bicknell</td></tr>\n",
       "<tr><td>Andy Luther</td></tr>\n",
       "<tr><td>Anthony Michael Hall</td></tr>\n",
       "<tr><td>Ariyon Bakare</td></tr>\n",
       "<tr><td>Beatrice Rosen</td></tr>\n",
       "<tr><td>Bill Smille</td></tr>\n",
       "<tr><td>Brandon Lambdin</td></tr>\n",
       "<tr><td>Bronson Webb</td></tr>\n",
       "<tr><td>Chin Han</td></tr>\n",
       "<tr><td>Christian Bale</td></tr>\n",
       "<tr><td>Chucky Venn</td></tr>\n",
       "<tr><td>Cillian Murphy</td></tr>\n",
       "<tr><td>Colin McFarlane</td></tr>\n",
       "<tr><td>Craig Heaney</td></tr>\n",
       "<tr><td>Crhis Perschler</td></tr>\n",
       "<tr><td>Dale RIvera</td></tr>\n",
       "<tr><td>Daryl Satcher</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+--------------------+\n",
       "|                name|\n",
       "+--------------------+\n",
       "|       Aaron Eckhart|\n",
       "|     Adam Kalesperis|\n",
       "|         Aidan Feore|\n",
       "|     Andrew Bicknell|\n",
       "|         Andy Luther|\n",
       "|Anthony Michael Hall|\n",
       "|       Ariyon Bakare|\n",
       "|      Beatrice Rosen|\n",
       "|         Bill Smille|\n",
       "|     Brandon Lambdin|\n",
       "|        Bronson Webb|\n",
       "|            Chin Han|\n",
       "|      Christian Bale|\n",
       "|         Chucky Venn|\n",
       "|      Cillian Murphy|\n",
       "|     Colin McFarlane|\n",
       "|        Craig Heaney|\n",
       "|     Crhis Perschler|\n",
       "|         Dale RIvera|\n",
       "|       Daryl Satcher|\n",
       "+--------------------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_with_actors = movies.join(actors, movies.mid == actors.mid)\n",
    "movies_title_actors = movies_with_actors.select('title','name')\n",
    "\n",
    "cast_TheDarkKnight = movies_title_actors.filter(movies_title_actors.title == 'The Dark Knight').sort(movies_title_actors.name.asc())\n",
    "only_cast = cast_TheDarkKnight.select('name')\n",
    "#only_cast.show(only_cast.count(), truncate=False)\n",
    "only_cast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Print the distinct genres in the database and their corresponding number of movies N where N is greater than 1000, sorted in the ascending order of N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>genre</th><th>countMovies</th></tr>\n",
       "<tr><td>Adventure</td><td>1003</td></tr>\n",
       "<tr><td>Crime</td><td>1086</td></tr>\n",
       "<tr><td>Action</td><td>1445</td></tr>\n",
       "<tr><td>Romance</td><td>1644</td></tr>\n",
       "<tr><td>Thriller</td><td>1664</td></tr>\n",
       "<tr><td>Comedy</td><td>3566</td></tr>\n",
       "<tr><td>Drama</td><td>5076</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---------+-----------+\n",
       "|    genre|countMovies|\n",
       "+---------+-----------+\n",
       "|Adventure|       1003|\n",
       "|    Crime|       1086|\n",
       "|   Action|       1445|\n",
       "|  Romance|       1644|\n",
       "| Thriller|       1664|\n",
       "|   Comedy|       3566|\n",
       "|    Drama|       5076|\n",
       "+---------+-----------+"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_genres = genres.rdd.map(lambda x: (x.genre,1)).reduceByKey(lambda a,b: a+b).filter(lambda x: (int(x[1]) > 1000))\n",
    "#reduced_genres.takeOrdered(20, key = lambda x: -x[1])\n",
    "reduced_genresdf = reduced_genres.toDF(['genre', 'countMovies']).sort('countMovies')\n",
    "reduced_genresdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. For each year, print the movie title, year, and rating, sorted in the ascending order of year and the descending order of movie rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>title</th><th>year</th><th>rating</th></tr>\n",
       "<tr><td>The Great Train R...</td><td>1903</td><td>0</td></tr>\n",
       "<tr><td>The Birth of a Na...</td><td>1915</td><td>3.3</td></tr>\n",
       "<tr><td>Intolerance: Love...</td><td>1916</td><td>3.8</td></tr>\n",
       "<tr><td>The Immigrant</td><td>1917</td><td>0</td></tr>\n",
       "<tr><td>Otets Sergiy</td><td>1917</td><td>0</td></tr>\n",
       "<tr><td>A Dog&#x27;s Life</td><td>1918</td><td>0</td></tr>\n",
       "<tr><td>Broken Blossoms o...</td><td>1919</td><td>3.7</td></tr>\n",
       "<tr><td>Die Spinnen, 1. T...</td><td>1919</td><td>0</td></tr>\n",
       "<tr><td>Male and Female</td><td>1919</td><td>0</td></tr>\n",
       "<tr><td>Das Cabinet des D...</td><td>1920</td><td>4.1</td></tr>\n",
       "<tr><td>Der Golem, wie er...</td><td>1920</td><td>0</td></tr>\n",
       "<tr><td>The Saphead</td><td>1920</td><td>0</td></tr>\n",
       "<tr><td>Way Down East</td><td>1920</td><td>0</td></tr>\n",
       "<tr><td>Orphans of the Storm</td><td>1921</td><td>0</td></tr>\n",
       "<tr><td>The Goat</td><td>1921</td><td>0</td></tr>\n",
       "<tr><td>Dr. Mabuse, der S...</td><td>1922</td><td>4.1</td></tr>\n",
       "<tr><td>Dr. Mabuse, der S...</td><td>1922</td><td>4.1</td></tr>\n",
       "<tr><td>Nosferatu, eine S...</td><td>1922</td><td>3.9</td></tr>\n",
       "<tr><td>Häxan</td><td>1922</td><td>3.8</td></tr>\n",
       "<tr><td>Nanook of the North</td><td>1922</td><td>3.7</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+--------------------+----+------+\n",
       "|               title|year|rating|\n",
       "+--------------------+----+------+\n",
       "|The Great Train R...|1903|     0|\n",
       "|The Birth of a Na...|1915|   3.3|\n",
       "|Intolerance: Love...|1916|   3.8|\n",
       "|       The Immigrant|1917|     0|\n",
       "|        Otets Sergiy|1917|     0|\n",
       "|        A Dog's Life|1918|     0|\n",
       "|Broken Blossoms o...|1919|   3.7|\n",
       "|Die Spinnen, 1. T...|1919|     0|\n",
       "|     Male and Female|1919|     0|\n",
       "|Das Cabinet des D...|1920|   4.1|\n",
       "|       Way Down East|1920|     0|\n",
       "|         The Saphead|1920|     0|\n",
       "|Der Golem, wie er...|1920|     0|\n",
       "|            The Goat|1921|     0|\n",
       "|Orphans of the Storm|1921|     0|\n",
       "|Dr. Mabuse, der S...|1922|   4.1|\n",
       "|Dr. Mabuse, der S...|1922|   4.1|\n",
       "|Nosferatu, eine S...|1922|   3.9|\n",
       "|               Häxan|1922|   3.8|\n",
       "| Nanook of the North|1922|   3.7|\n",
       "+--------------------+----+------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_sorted= movies.sort(movies.year.asc(), movies.rating.desc())\n",
    "movies_sortedFiltered = movies_sorted.select('title', 'year', 'rating')\n",
    "movies_sortedFiltered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Critiques say that some words used in tags to convey emotions are very recurrent. To convey positive and negative emotions, the words ‘good’ and ‘bad’, respectively, are used predominantly in tags. Print all movie titles whose audience opinion is split (i.e., has at least one audience who expresses positive emotion and at least one who expresses negative emotion)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>title</th></tr>\n",
       "<tr><td>Twilight</td></tr>\n",
       "<tr><td>The Forgotten</td></tr>\n",
       "<tr><td>Starship Troopers</td></tr>\n",
       "<tr><td>Bridget Jones&#x27;s D...</td></tr>\n",
       "<tr><td>Howard the Duck</td></tr>\n",
       "<tr><td>Hercules in New York</td></tr>\n",
       "<tr><td>C.H.U.D.</td></tr>\n",
       "<tr><td>The Wicker Man</td></tr>\n",
       "<tr><td>Ocean&#x27;s Eleven</td></tr>\n",
       "<tr><td>Return of the Kil...</td></tr>\n",
       "<tr><td>From Dusk Till Dawn</td></tr>\n",
       "<tr><td>Kakushi-toride no...</td></tr>\n",
       "<tr><td>Xanadu</td></tr>\n",
       "<tr><td>Lawrence of Arabia</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------------------+\n",
       "|               title|\n",
       "+--------------------+\n",
       "|            Twilight|\n",
       "|       The Forgotten|\n",
       "|   Starship Troopers|\n",
       "|Bridget Jones's D...|\n",
       "|     Howard the Duck|\n",
       "|Hercules in New York|\n",
       "|            C.H.U.D.|\n",
       "|      The Wicker Man|\n",
       "|      Ocean's Eleven|\n",
       "|Return of the Kil...|\n",
       "| From Dusk Till Dawn|\n",
       "|Kakushi-toride no...|\n",
       "|              Xanadu|\n",
       "|  Lawrence of Arabia|\n",
       "+--------------------+"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_with_tags = movies.join(tags, ['mid']).join(tagNames, ['tid'])\n",
    "movies_with_tags_onlyGood = movies_with_tags.filter(movies_with_tags.tag.contains( 'good'))\n",
    "movies_with_tags_onlyBad = movies_with_tags.filter(movies_with_tags.tag.contains( 'bad'))\n",
    "\n",
    "movies_with_tags_onlyGoodBad = (movies_with_tags_onlyGood.select('mid','title')).intersect(movies_with_tags_onlyBad.select('mid','title'))\n",
    "result = movies_with_tags_onlyGoodBad.select('title')\n",
    "result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. One would expect that the movie with the highest number of user ratings is either the highest rated movie or perhaps the lowest rated movie. Let’s find out if this is the case here:\n",
    "\n",
    "#### 6.1 : Print all information (mid, title, year, num ratings, rating) for the movie(s) with the highest number of ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>mid</th><th>title</th><th>year</th><th>rating</th><th>num_ratings</th></tr>\n",
       "<tr><td>4201</td><td>Pirates of the Ca...</td><td>2007</td><td>3.8</td><td>1768593</td></tr>\n",
       "<tr><td>53125</td><td>Pirates of the Ca...</td><td>2007</td><td>3.8</td><td>1768593</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----+--------------------+----+------+-----------+\n",
       "|  mid|               title|year|rating|num_ratings|\n",
       "+-----+--------------------+----+------+-----------+\n",
       "| 4201|Pirates of the Ca...|2007|   3.8|    1768593|\n",
       "|53125|Pirates of the Ca...|2007|   3.8|    1768593|\n",
       "+-----+--------------------+----+------+-----------+"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_ratings = movies.filter(movies.num_ratings != '\\\\N').withColumn('num_ratings', col('num_ratings').cast('int'))\n",
    "max_num_rating = num_ratings.select(max('num_ratings'))\n",
    "\n",
    "movies_with_max_num_ratings = movies.filter(movies.num_ratings == max_num_rating.collect()[0][0])\n",
    "movies_with_max_num_ratings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2: Print all information (mid, title, year, num ratings, rating) for the movie(s) with the highest rating (include tuples that tie), sorted by the ascending order of movie id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>mid</th><th>title</th><th>year</th><th>rating</th><th>num_ratings</th></tr>\n",
       "<tr><td>4311</td><td>1732 Høtten</td><td>1998</td><td>5</td><td>5</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----+-----------+----+------+-----------+\n",
       "| mid|      title|year|rating|num_ratings|\n",
       "+----+-----------+----+------+-----------+\n",
       "|4311|1732 Høtten|1998|     5|          5|\n",
       "+----+-----------+----+------+-----------+"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_ratings = movies.filter(movies.rating != '\\\\N').withColumn('rating', col('rating').cast('double'))\n",
    "max_rating = num_ratings.select(max('rating'))\n",
    "movies_with_max_ratings = movies.filter(movies.rating == max_rating.collect()[0][0])\n",
    "movies_with_max_ratings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3: Is (Are) the movie(s) with the most number of user ratings among these highest rated movies? Print the output of the query that will check our conjecture (i.e., your query will print the movie(s) that has (have) the highest number of ratings as well as the highest rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>mid</th><th>title</th><th>year</th><th>rating</th><th>num_ratings</th></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---+-----+----+------+-----------+\n",
       "|mid|title|year|rating|num_ratings|\n",
       "+---+-----+----+------+-----------+\n",
       "+---+-----+----+------+-----------+"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = movies_with_max_num_ratings.intersect(movies_with_max_ratings)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.4: Print all information (mid, title, year, num ratings, rating) for the movie(s) with the lowest rating (include tuples that tie), sorted by the ascending order of movie id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>mid</th><th>title</th><th>year</th><th>rating</th><th>num_ratings</th></tr>\n",
       "<tr><td>32</td><td>Twelve Monkeys</td><td>1995</td><td>0</td><td>0</td></tr>\n",
       "<tr><td>33</td><td>Wings of Courage</td><td>1995</td><td>0</td><td>0</td></tr>\n",
       "<tr><td>39</td><td>Clueless</td><td>1995</td><td>0</td><td>0</td></tr>\n",
       "<tr><td>56</td><td>Kids of the Round...</td><td>1997</td><td>0</td><td>0</td></tr>\n",
       "<tr><td>59</td><td>Le confessionnal</td><td>1995</td><td>0</td><td>0</td></tr>\n",
       "<tr><td>61</td><td>Eye for an Eye</td><td>1996</td><td>0</td><td>0</td></tr>\n",
       "<tr><td>63</td><td>Don&#x27;t Be a Menace...</td><td>1996</td><td>0</td><td>0</td></tr>\n",
       "<tr><td>69</td><td>Friday</td><td>1995</td><td>0</td><td>0</td></tr>\n",
       "<tr><td>115</td><td>Le bonheur est da...</td><td>1995</td><td>0</td><td>0</td></tr>\n",
       "<tr><td>126</td><td>The Neverending S...</td><td>1994</td><td>0</td><td>0</td></tr>\n",
       "<tr><td>128</td><td>Jupiter&#x27;s Wife</td><td>1995</td><td>0</td><td>0</td></tr>\n",
       "<tr><td>129</td><td>Pie in the Sky</td><td>1996</td><td>0</td><td>0</td></tr>\n",
       "<tr><td>134</td><td>Sonic Outlaws</td><td>1995</td><td>0</td><td>0</td></tr>\n",
       "<tr><td>139</td><td>Hard Target</td><td>1993</td><td>0</td><td>0</td></tr>\n",
       "<tr><td>178</td><td>Love &amp; Human Remains</td><td>1993</td><td>0</td><td>0</td></tr>\n",
       "<tr><td>179</td><td>Mad Love</td><td>1995</td><td>0</td><td>0</td></tr>\n",
       "<tr><td>184</td><td>Nadja</td><td>1994</td><td>0</td><td>0</td></tr>\n",
       "<tr><td>189</td><td>The Reckless Moment</td><td>1949</td><td>0</td><td>0</td></tr>\n",
       "<tr><td>190</td><td>Fail-Safe</td><td>1964</td><td>0</td><td>0</td></tr>\n",
       "<tr><td>220</td><td>Castle Freak</td><td>1995</td><td>0</td><td>0</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+---+--------------------+----+------+-----------+\n",
       "|mid|               title|year|rating|num_ratings|\n",
       "+---+--------------------+----+------+-----------+\n",
       "| 32|      Twelve Monkeys|1995|     0|          0|\n",
       "| 33|    Wings of Courage|1995|     0|          0|\n",
       "| 39|            Clueless|1995|     0|          0|\n",
       "| 56|Kids of the Round...|1997|     0|          0|\n",
       "| 59|    Le confessionnal|1995|     0|          0|\n",
       "| 61|      Eye for an Eye|1996|     0|          0|\n",
       "| 63|Don't Be a Menace...|1996|     0|          0|\n",
       "| 69|              Friday|1995|     0|          0|\n",
       "|115|Le bonheur est da...|1995|     0|          0|\n",
       "|126|The Neverending S...|1994|     0|          0|\n",
       "|128|      Jupiter's Wife|1995|     0|          0|\n",
       "|129|      Pie in the Sky|1996|     0|          0|\n",
       "|134|       Sonic Outlaws|1995|     0|          0|\n",
       "|139|         Hard Target|1993|     0|          0|\n",
       "|178|Love & Human Remains|1993|     0|          0|\n",
       "|179|            Mad Love|1995|     0|          0|\n",
       "|184|               Nadja|1994|     0|          0|\n",
       "|189| The Reckless Moment|1949|     0|          0|\n",
       "|190|           Fail-Safe|1964|     0|          0|\n",
       "|220|        Castle Freak|1995|     0|          0|\n",
       "+---+--------------------+----+------+-----------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_ratings = movies.filter(movies.rating != '\\\\N').withColumn('rating', col('rating').cast('double'))\n",
    "min_rating = num_ratings.select(min('rating'))\n",
    "movies_with_min_ratings = movies.filter(movies.rating == min_rating.collect()[0][0])\n",
    "movies_with_min_ratings\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.5: Is (Are) the movie(s) with the most number of user ratings among these lowest rated movies? Print the output of the query that will check our conjecture (i.e., your query will print the movie(s) that has (have) the highest number of ratings as well as the lowest rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>mid</th><th>title</th><th>year</th><th>rating</th><th>num_ratings</th></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---+-----+----+------+-----------+\n",
       "|mid|title|year|rating|num_ratings|\n",
       "+---+-----+----+------+-----------+\n",
       "+---+-----+----+------+-----------+"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = movies_with_max_num_ratings.intersect(movies_with_min_ratings)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.6: In conclusion, is our hypothesis or conjecture true for the MovieLens database?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No, the results of query 6.3 and 6.5 show that both the intersection of max_num_ratings and max_rating/min_rating are empty! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Print the movie title, year, and rating of the lowest and highest movies for each year in 2005 – 2011, inclusive, in the ascending order of year. In case of a tie, print the records in the ascending order of title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>title</th><th>year</th><th>rating</th></tr>\n",
       "<tr><td>Alone in the Dark</td><td>2005</td><td>2.1</td></tr>\n",
       "<tr><td>Alone in the Dark</td><td>2005</td><td>2.1</td></tr>\n",
       "<tr><td>Alone in the Dark</td><td>2005</td><td>2.1</td></tr>\n",
       "<tr><td>Son of the Mask</td><td>2005</td><td>2.1</td></tr>\n",
       "<tr><td>No Direction Home...</td><td>2005</td><td>4.3</td></tr>\n",
       "<tr><td>Basic Instinct 2</td><td>2006</td><td>2.5</td></tr>\n",
       "<tr><td>Basic Instinct 2</td><td>2006</td><td>2.5</td></tr>\n",
       "<tr><td>Bug</td><td>2006</td><td>2.5</td></tr>\n",
       "<tr><td>Bug</td><td>2006</td><td>2.5</td></tr>\n",
       "<tr><td>Doogal</td><td>2006</td><td>2.5</td></tr>\n",
       "<tr><td>Das Leben der And...</td><td>2006</td><td>4.4</td></tr>\n",
       "<tr><td>D-War</td><td>2007</td><td>2.3</td></tr>\n",
       "<tr><td>Byôsoku 5 senchim...</td><td>2007</td><td>4.3</td></tr>\n",
       "<tr><td>No End in Sight</td><td>2007</td><td>4.3</td></tr>\n",
       "<tr><td>Pete Seeger: The ...</td><td>2007</td><td>4.3</td></tr>\n",
       "<tr><td>War Dance</td><td>2007</td><td>4.3</td></tr>\n",
       "<tr><td>Asylum</td><td>2008</td><td>2.2</td></tr>\n",
       "<tr><td>Asylum</td><td>2008</td><td>2.2</td></tr>\n",
       "<tr><td>The Dark Knight</td><td>2008</td><td>4.5</td></tr>\n",
       "<tr><td>Miss March</td><td>2009</td><td>2.7</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+--------------------+----+------+\n",
       "|               title|year|rating|\n",
       "+--------------------+----+------+\n",
       "|   Alone in the Dark|2005|   2.1|\n",
       "|   Alone in the Dark|2005|   2.1|\n",
       "|   Alone in the Dark|2005|   2.1|\n",
       "|     Son of the Mask|2005|   2.1|\n",
       "|No Direction Home...|2005|   4.3|\n",
       "|    Basic Instinct 2|2006|   2.5|\n",
       "|    Basic Instinct 2|2006|   2.5|\n",
       "|                 Bug|2006|   2.5|\n",
       "|                 Bug|2006|   2.5|\n",
       "|              Doogal|2006|   2.5|\n",
       "|Das Leben der And...|2006|   4.4|\n",
       "|               D-War|2007|   2.3|\n",
       "|Byôsoku 5 senchim...|2007|   4.3|\n",
       "|     No End in Sight|2007|   4.3|\n",
       "|Pete Seeger: The ...|2007|   4.3|\n",
       "|           War Dance|2007|   4.3|\n",
       "|              Asylum|2008|   2.2|\n",
       "|              Asylum|2008|   2.2|\n",
       "|     The Dark Knight|2008|   4.5|\n",
       "|          Miss March|2009|   2.7|\n",
       "+--------------------+----+------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_2005_2011 = movies.filter((movies.year >= 2005) & (movies.year <= 2011))\n",
    "movies_list = []\n",
    "\n",
    "for year in range(2005,2012):\n",
    "    ratings = movies_2005_2011.filter((movies_2005_2011.year == year) & (movies_2005_2011.num_ratings != '\\\\N') & (movies_2005_2011.num_ratings > 0)).withColumn('rating', col('rating').cast('double'))\n",
    "    min_rating = ratings.select(min('rating'))\n",
    "    max_rating = ratings.select(max('rating'))\n",
    "    result_min = ratings.filter(ratings.rating == min_rating.collect()[0][0]).sort(ratings.title)\n",
    "    result_max = ratings.filter(ratings.rating == max_rating.collect()[0][0]).sort(ratings.title)\n",
    "    final_result = result_min.union(result_max).select('title','year', 'rating')\n",
    "    movies_list.extend(final_result.collect())\n",
    "\n",
    "rdd = sc.parallelize(movies_list)\n",
    "result = rdd.toDF()\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Let us find out who are the ‘no flop’ actors. A ‘no flop’ actor can be defined as one who has played only in movies which have a rating greater than or equal to 4. We split this problem into the following steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8.1 Create a view called high ratings which contains the distinct names of all actors who have played in movies with a rating greater than or equal to 4. Similarly, create a view called low ratings which contains the distinct names of all actors who have played in movies with a rating less than 4. Print the number of rows in each view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87032"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_with_actors = movies.join(actors,['mid']).withColumn('rating', col('rating').cast('double'))\n",
    "\n",
    "high_ratings = movies_with_actors.filter(movies_with_actors.rating >= 4.0).select('name').distinct()\n",
    "low_ratings = movies_with_actors.filter(movies_with_actors.rating < 4.0).select('name').distinct()\n",
    "high_ratings.count()\n",
    "low_ratings.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8.2 Use the above views to print the number of ‘no flop’ actors in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7015"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = high_ratings.subtract(low_ratings)\n",
    "result.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 8.3 For each ‘no flop’ actor, print the name of the actor and the number of movies N that he/she played in, sorted in descending order of N. Finally, print the top10 only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>name</th><th>countMovies</th></tr>\n",
       "<tr><td>Nikolai Grinko</td><td>8</td></tr>\n",
       "<tr><td>Paul Frankeur</td><td>7</td></tr>\n",
       "<tr><td>John Cazale</td><td>7</td></tr>\n",
       "<tr><td>Tsutomu Yamazaki</td><td>6</td></tr>\n",
       "<tr><td>Gunnel Lindblom</td><td>6</td></tr>\n",
       "<tr><td>Allan Garcia</td><td>6</td></tr>\n",
       "<tr><td>Kuniko Miyake</td><td>6</td></tr>\n",
       "<tr><td>Anatoli Solonitsin</td><td>5</td></tr>\n",
       "<tr><td>Timothy T. Mitchum</td><td>5</td></tr>\n",
       "<tr><td>Megan Gallagher</td><td>5</td></tr>\n",
       "<tr><td>Michael Drayer</td><td>4</td></tr>\n",
       "<tr><td>Bilal Bishop</td><td>4</td></tr>\n",
       "<tr><td>Yvette Bodrick</td><td>4</td></tr>\n",
       "<tr><td>Travis Veada</td><td>4</td></tr>\n",
       "<tr><td>Michael Nyqvist</td><td>4</td></tr>\n",
       "<tr><td>Ellen Bahl</td><td>4</td></tr>\n",
       "<tr><td>Jindai Joseph</td><td>4</td></tr>\n",
       "<tr><td>Jamia Simone Nash</td><td>4</td></tr>\n",
       "<tr><td>Dirk Zeelenberg</td><td>4</td></tr>\n",
       "<tr><td>Tyler McGuckin</td><td>4</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+-------------------+-----------+\n",
       "|               name|countMovies|\n",
       "+-------------------+-----------+\n",
       "|     Nikolai Grinko|          8|\n",
       "|      Paul Frankeur|          7|\n",
       "|        John Cazale|          7|\n",
       "|    Gunnel Lindblom|          6|\n",
       "|       Allan Garcia|          6|\n",
       "|      Kuniko Miyake|          6|\n",
       "|   Tsutomu Yamazaki|          6|\n",
       "| Anatoli Solonitsin|          5|\n",
       "| Timothy T. Mitchum|          5|\n",
       "|    Megan Gallagher|          5|\n",
       "|     Tyler McGuckin|          4|\n",
       "|    Michael Nyqvist|          4|\n",
       "|     Yvette Bodrick|          4|\n",
       "|         Olaf Storm|          4|\n",
       "|Joyce Walker Jospeh|          4|\n",
       "|      Jindai Joseph|          4|\n",
       "|    Dirk Zeelenberg|          4|\n",
       "|     Michael Drayer|          4|\n",
       "|       Aaron Staton|          4|\n",
       "|  Jamia Simone Nash|          4|\n",
       "+-------------------+-----------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noFlopactors_with_mid = actors.join(result,['name'])\n",
    "\n",
    "reduced_actors = noFlopactors_with_mid.rdd.map(lambda x: (x.name,1)).reduceByKey(lambda a,b: a+b)\n",
    "reduced_actors_df = reduced_actors.toDF(['name', 'countMovies'])\n",
    "final_result = reduced_actors_df.withColumn('countMovies', col('countMovies').cast('int')).sort(reduced_actors_df.countMovies.desc())\n",
    "final_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 9. Let us find out who is the actor with the highest ‘longevity.’ Print the name of the actor/actress who has been playing in movies for the longest period of time (i.e., the time interval between their first movie and their last movie is the greatest)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>name</th><th>difference</th></tr>\n",
       "<tr><td>Morgan Jones</td><td>102</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------------+----------+\n",
       "|        name|difference|\n",
       "+------------+----------+\n",
       "|Morgan Jones|       102|\n",
       "+------------+----------+"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_with_actors = movies.join(actors,['mid']).withColumn('year', col('year').cast('int'))\n",
    "partial_result = movies_with_actors.select('name','year').distinct()\n",
    "\n",
    "result_max = partial_result.groupBy('name').max('year').withColumnRenamed('max(year)', 'recentYear')\n",
    "result_min = partial_result.groupBy('name').min('year').withColumnRenamed('min(year)', 'firstYear')\n",
    "result_join = result_min.join(result_max,['name'])\n",
    "result = result_join.select('name',result_join.recentYear-result_join.firstYear).withColumnRenamed('(recentYear - firstYear)', 'difference')\n",
    "max_difference = result.select(max('difference'))\n",
    "final_result = result.filter(result.difference == max_difference.collect()[0][0])\n",
    "final_result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 10. Let us find the close friends of Annette Nicole. Print the names of all actors who have starred in (at least) all movies in which Annette Nicole has starred in. Note that it is OK if these actors have starred in more movies than Annette Nicole has played in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 10.1 First, create a view called co_actors, which returns the distinct names of actors who played in at least one movie with Annette Nicole. Print the number of rows in this view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_with_actors = movies.join(actors,['mid'])\n",
    "movies_with_Annette = movies_with_actors.filter(movies_with_actors.name == 'Annette Nicole')\n",
    "movies_with_Annette_mid = movies_with_Annette.select('mid')\n",
    "movies_with_cast_and_Annette = actors.join(movies_with_Annette_mid,['mid'])\n",
    "co_actors = movies_with_cast_and_Annette.select('name').distinct()\n",
    "co_actors.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 10.2 Second, create a view called all_combinations which returns all possible combinations of co_actors and the movie ids in which Annette Nicole played. Print the number of rows in this view. Note how that this view contains fake (co_actor, mid) combinations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "537"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partial_all_combinations = movies_with_Annette.withColumnRenamed('name', 'nameAnnette').crossJoin(co_actors)\n",
    "all_combinations = partial_all_combinations.select('mid','name')\n",
    "all_combinations.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 10.3 Third, create a view called non_existent from the view all_combinations by removing all legitimate (co_actor,mid) pairs (i.e., pairs that exist in the actors table). Print the number of rows in this view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "239"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actors_real = actors.select('mid', 'name')\n",
    "\n",
    "non_existent = all_combinations.subtract(actors_real)\n",
    "#non_existent.select('name').distinct().count()\n",
    "non_existent.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 10.4 Finally, from the view co_actors, eliminate the distinct actors that appear in the view non_extistent. Print the names of all co_actors except Annette Nicole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>name</th></tr>\n",
       "<tr><td>Kristen Connolly</td></tr>\n",
       "<tr><td>Christian Perry</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----------------+\n",
       "|            name|\n",
       "+----------------+\n",
       "|Kristen Connolly|\n",
       "| Christian Perry|\n",
       "+----------------+"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = co_actors.subtract(non_existent.select('name'))\n",
    "final.filter(final.name != 'Annette Nicole')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 11. Let us find out who is the most social actor. A social actor is the one with the highest number of distinct co-actors. We will break this into two sub-tasks:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 11.1 For the actor Tom Cruise, print his name and the number of distinct co-actors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>name</th><th>countCoActors</th></tr>\n",
       "<tr><td>Tom Cruise</td><td>1238</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----------+-------------+\n",
       "|      name|countCoActors|\n",
       "+----------+-------------+\n",
       "|Tom Cruise|         1238|\n",
       "+----------+-------------+"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_with_Tom = actors.filter(actors.name == 'Tom Cruise').select('mid','name') \n",
    "movies_with_coActors = movies_with_Tom.join(actors.withColumnRenamed('name', 'nameCoActors'),['mid'])\n",
    "final_coActors_Tom = movies_with_coActors.filter(movies_with_coActors.nameCoActors != 'Tom Cruise').select('name', 'nameCoActors').distinct().groupBy('name').count().withColumnRenamed('count', 'countCoActors')\n",
    "final_coActors_Tom\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 11.2 For each actor, compute the number of distinct co-actors. For the highest such number, print the name of the actor and the number of distinct co-actors. In case of a tie, print the records sorted in alphabetical order by name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>_1</th><th>_2</th></tr>\n",
       "<tr><td>Oliver Platt</td><td>831</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------------+---+\n",
       "|          _1| _2|\n",
       "+------------+---+\n",
       "|Oliver Platt|831|\n",
       "+------------+---+"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_social_actor = []\n",
    "maxCoActors = 0\n",
    "actors_list = actors.select('name').distinct().collect()\n",
    "\n",
    "for actor in actors_list:\n",
    "    movies_with_specific_actor = actors.filter(actors.name == actor[0]).select('mid','name') \n",
    "    movies_with_coActors = movies_with_specific_actor.join(actors.withColumnRenamed('name', 'nameCoActors'),['mid'])\n",
    "    final_coActors_specific_actor = movies_with_coActors.filter(movies_with_coActors.nameCoActors != actor[0]).select('name', 'nameCoActors').distinct().groupBy('name').count().withColumnRenamed('count', 'countCoActors')\n",
    "    most_social_actor.append((actor[0], final_coActors_specific_actor.collect()[0][1]))\n",
    "    \n",
    "rdd = sc.parallelize(most_social_actor)\n",
    "result = rdd.toDF()\n",
    "max_coActors = result.select(max('_2'))\n",
    "\n",
    "final_result = result.filter(result._2 == max_coActors.collect()[0][0]) \n",
    "final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>name</th><th>countCoActors</th></tr>\n",
       "<tr><td>Samuel L. Jackson</td><td>1824</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----------------+-------------+\n",
       "|             name|countCoActors|\n",
       "+-----------------+-------------+\n",
       "|Samuel L. Jackson|         1824|\n",
       "+-----------------+-------------+"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_actors = actors.rdd.map(lambda x: (x.mid,1)).reduceByKey(lambda a,b: a+b)\n",
    "result_countActors = reduced_actors.toDF().withColumnRenamed('_1','mid').withColumnRenamed('_2','countActors')\n",
    "movies_with_countActors = result_countActors.join(actors,['mid']).select('mid','countActors','name')\n",
    "\n",
    "movies_with_countActors_reduced = movies_with_countActors.rdd.map(lambda x: (x.name,x.countActors-1)).reduceByKey(lambda a,b: a+b)\n",
    "result_countActors = movies_with_countActors_reduced.toDF().withColumnRenamed('_1','name').withColumnRenamed('_2','countCoActors')\n",
    "\n",
    "\n",
    "couples_coActors = actors.join(actors.withColumnRenamed('name','coActor'),['mid']).groupBy('name','coActor').count().withColumnRenamed('count', 'countCoActors')\n",
    "result_partial_couples = couples_coActors.filter(couples_coActors.name != couples_coActors.coActor).select('name', 'coActor',couples_coActors.countCoActors-1).withColumnRenamed('(countCoActors - 1)', 'duplicates').withColumn('duplicates', col('duplicates').cast('int'))\n",
    "result_couples = result_partial_couples.groupBy('name').sum('duplicates').withColumnRenamed('sum(duplicates)', 'duplicates')\n",
    "\n",
    "r= result_countActors.join(result_couples,['name'])\n",
    "final_r = r.select('name', r.countCoActors - r.duplicates).withColumnRenamed('(countCoActors - duplicates)','countCoActors')\n",
    "max_coActors = final_r.select(max('countCoActors'))\n",
    "#final_r.filter(final_r.name == 'Tom Cruise') --> 1238 it's correct!\n",
    "final_result = final_r.filter(final_r.countCoActors == max_coActors.collect()[0][0]) \n",
    "final_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 12. We will now write some queries for a Content-Based Movie Recommendation System such as NetFlix. However, in this project we shall deploy a simple algorithm that may or may not produce optimal recommendations. Content-based recommendations focus on the properties of items, in our case movies. The similarity of two movies is determined by measuring the similarity of their properties. For a movie item, we shall consider the following five properties: actors, tags, genres, year, and rating. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Given two movies X and Y, the similarity of Y to X, sim(X,Y), can be computed as: (fraction of common actors + fraction of common tags + fraction of common genres + age gap + rating gap) /5 where fraction is the number of common elements between X and Y divided by the number of elements of X, age gap is the normalized difference between the production years of X and Y, and rating gap is the normalized difference between the ratings of X and Y. Intuitively, the smaller the gaps are, the better (since movies of the same decade and rating are more likely to be similar). Moreover, note that we divide by five because each property is given an equal weight of 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Given a user who is known to like the movie ‘Mr. & Mrs. Smith’, write a query that prints the movie title, rating, and similarity percentage (i.e., similarity * 100) for the top 10 movies that are most similar to the ‘Mr. & Mrs. Smith’ movie, ordered by the similarity percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "minYear = int(movies.select(min(movies.year)).collect()[0][0])\n",
    "maxYear = int(movies.select(max(movies.year)).collect()[0][0])\n",
    "maxRating = float(movies.filter(movies.rating != '\\\\N').select(max(movies.rating)).collect()[0][0])\n",
    "\n",
    "def get_mid(movie):\n",
    "    return movies.filter(movies.title == movie).select('mid').collect()[0][0]\n",
    "\n",
    "def get_num_actor(mid_film):\n",
    "    return len(actors.filter(actors.mid == mid_film).select('name').collect())\n",
    "\n",
    "def get_num_tags(mid_film):\n",
    "    return len(tags.filter(tags.mid == mid_film).select('tid').distinct().collect())\n",
    "\n",
    "def get_num_genres(mid_film):\n",
    "    return len(genres.filter(genres.mid == mid_film).select('genre').distinct().collect())\n",
    "\n",
    "def intersection_actors(mid_movie1, mid_movie2):\n",
    "    actorsMovie1 = actors.filter(actors.mid == mid_movie1).select('name')\n",
    "    actorsMovie2 = actors.filter(actors.mid == mid_movie2).select('name')\n",
    "    return len(actorsMovie1.intersect(actorsMovie2).collect())\n",
    "\n",
    "def intersection_tags(mid_movie1, mid_movie2):\n",
    "    tagsMovie1 = tags.filter(tags.mid == mid_movie1).select('tid')\n",
    "    tagsMovie2 = tags.filter(tags.mid == mid_movie2).select('tid')\n",
    "    return len(tagsMovie1.intersect(tagsMovie2).collect())\n",
    "\n",
    "def intersection_genres(mid_movie1, mid_movie2):\n",
    "    genreMovie1 = genres.filter(genres.mid == mid_movie1).select('genre')\n",
    "    genreMovie2 = genres.filter(genres.mid == mid_movie2).select('genre')\n",
    "    return len(genreMovie1.intersect(genreMovie2).collect())\n",
    "    \n",
    "def common_actors(movie1, movie2):\n",
    "    return intersection_actors(movie1, movie2)/get_num_actor(movie1)\n",
    "\n",
    "def common_tags(movie1, movie2):\n",
    "    return intersection_tags(movie1, movie2)/get_num_tags(movie1)\n",
    "\n",
    "def common_genres(movie1, movie2):\n",
    "    return intersection_genres(movie1, movie2)/get_num_genres(movie1)\n",
    "\n",
    "def age_gap(mid_movie1, mid_movie2):\n",
    "    year_movie1 = int(movies.filter(movies.mid == mid_movie1).select('year').collect()[0][0])\n",
    "    year_movie2 = int(movies.filter(movies.mid == mid_movie2).select('year').collect()[0][0])\n",
    "    difference = abs(year_movie1 - year_movie2) #check this site https://stats.stackexchange.com/questions/79706/normalizing-difference-between-two-real-values-to-0-1-interval \n",
    "    return 1 - (difference/maxYear)\n",
    "\n",
    "def rating_gap(mid_movie1, mid_movie2):\n",
    "    rating_movie1 = float(movies.filter(movies.mid == mid_movie1).select('rating').collect()[0][0])\n",
    "    rating_movie2 = float(movies.filter(movies.mid == mid_movie2).select('rating').collect()[0][0])\n",
    "    if rating_movie1 == '\\\\N' or rating_movie2 == '\\\\N':\n",
    "        difference = 0\n",
    "    else:\n",
    "        difference = abs(rating_movie1 - rating_movie2) #check this site https://stats.stackexchange.com/questions/79706/normalizing-difference-between-two-real-values-to-0-1-interval \n",
    "    return 1 - (difference/maxRating)\n",
    "\n",
    "def similarity_old(mid_movie1, mid_movie2):\n",
    "    return (common_actors(mid_movie1, mid_movie2)+common_tags(mid_movie1, mid_movie2)+common_genres(mid_movie1, mid_movie2) + age_gap(mid_movie1, mid_movie2) + rating_gap(mid_movie1, mid_movie2))/5\n",
    "\n",
    "\n",
    "#print('Similarity(Toy story, Toy story) =', float(\"{:.2f}\".format(similarity(get_mid('Toy story'),get_mid('Toy story')) *100)) , '%')\n",
    "#print('Similarity(Toy story, Mr. & Mrs. Smith) = ',float(\"{:.2f}\".format( similarity(get_mid('Toy story'),get_mid( 'Mr. & Mrs. Smith')) *100)) , '%')\n",
    "\n",
    "\n",
    "# start calculating top 10 similar movies \n",
    "# cross join of movies\n",
    "cross_join_movies = movies.withColumnRenamed('mid','mid1').crossJoin(movies.withColumnRenamed('mid','mid2')).select('mid1','mid2')\n",
    "#remove duplicates\n",
    "cross_join_without_duplicates = cross_join_movies.filter(cross_join_movies.mid1 != cross_join_movies.mid2)\n",
    "#map\n",
    "#map_movies = cross_join_without_duplicates.limit(10).rdd.map(lambda x: ((x.mid1, x.mid2),similarity(x.mid1,x.mid2)))\n",
    "#map_movies.take(5)\n",
    "\n",
    "#mid_movieMrSmith = get_mid('Mr. & Mrs. Smith')\n",
    "#movies_without_MrSmith = movies.filter(movies.title != 'Mr. & Mrs. Smith').collect()\n",
    "\n",
    "#for mid in movies_without_MrSmith[0][0]:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/luca/Scrivania/BigData-project/spark-3.0.2-bin-hadoop2.7/python/pyspark/serializers.py\", line 468, in dumps\n",
      "    return cloudpickle.dumps(obj, pickle_protocol)\n",
      "  File \"/home/luca/Scrivania/BigData-project/spark-3.0.2-bin-hadoop2.7/python/pyspark/cloudpickle.py\", line 1097, in dumps\n",
      "    cp.dump(obj)\n",
      "  File \"/home/luca/Scrivania/BigData-project/spark-3.0.2-bin-hadoop2.7/python/pyspark/cloudpickle.py\", line 357, in dump\n",
      "    return Pickler.dump(self, obj)\n",
      "  File \"/home/luca/anaconda3/lib/python3.7/pickle.py\", line 437, in dump\n",
      "    self.save(obj)\n",
      "  File \"/home/luca/anaconda3/lib/python3.7/pickle.py\", line 504, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/home/luca/anaconda3/lib/python3.7/pickle.py\", line 789, in save_tuple\n",
      "    save(element)\n",
      "  File \"/home/luca/anaconda3/lib/python3.7/pickle.py\", line 504, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/home/luca/Scrivania/BigData-project/spark-3.0.2-bin-hadoop2.7/python/pyspark/cloudpickle.py\", line 501, in save_function\n",
      "    self.save_function_tuple(obj)\n",
      "  File \"/home/luca/Scrivania/BigData-project/spark-3.0.2-bin-hadoop2.7/python/pyspark/cloudpickle.py\", line 730, in save_function_tuple\n",
      "    save(state)\n",
      "  File \"/home/luca/anaconda3/lib/python3.7/pickle.py\", line 504, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/home/luca/anaconda3/lib/python3.7/pickle.py\", line 859, in save_dict\n",
      "    self._batch_setitems(obj.items())\n",
      "  File \"/home/luca/anaconda3/lib/python3.7/pickle.py\", line 885, in _batch_setitems\n",
      "    save(v)\n",
      "  File \"/home/luca/anaconda3/lib/python3.7/pickle.py\", line 504, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/home/luca/anaconda3/lib/python3.7/pickle.py\", line 819, in save_list\n",
      "    self._batch_appends(obj)\n",
      "  File \"/home/luca/anaconda3/lib/python3.7/pickle.py\", line 843, in _batch_appends\n",
      "    save(x)\n",
      "  File \"/home/luca/anaconda3/lib/python3.7/pickle.py\", line 504, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/home/luca/Scrivania/BigData-project/spark-3.0.2-bin-hadoop2.7/python/pyspark/cloudpickle.py\", line 501, in save_function\n",
      "    self.save_function_tuple(obj)\n",
      "  File \"/home/luca/Scrivania/BigData-project/spark-3.0.2-bin-hadoop2.7/python/pyspark/cloudpickle.py\", line 730, in save_function_tuple\n",
      "    save(state)\n",
      "  File \"/home/luca/anaconda3/lib/python3.7/pickle.py\", line 504, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/home/luca/anaconda3/lib/python3.7/pickle.py\", line 859, in save_dict\n",
      "    self._batch_setitems(obj.items())\n",
      "  File \"/home/luca/anaconda3/lib/python3.7/pickle.py\", line 885, in _batch_setitems\n",
      "    save(v)\n",
      "  File \"/home/luca/anaconda3/lib/python3.7/pickle.py\", line 504, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/home/luca/anaconda3/lib/python3.7/pickle.py\", line 819, in save_list\n",
      "    self._batch_appends(obj)\n",
      "  File \"/home/luca/anaconda3/lib/python3.7/pickle.py\", line 846, in _batch_appends\n",
      "    save(tmp[0])\n",
      "  File \"/home/luca/anaconda3/lib/python3.7/pickle.py\", line 504, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/home/luca/Scrivania/BigData-project/spark-3.0.2-bin-hadoop2.7/python/pyspark/cloudpickle.py\", line 496, in save_function\n",
      "    self.save_function_tuple(obj)\n",
      "  File \"/home/luca/Scrivania/BigData-project/spark-3.0.2-bin-hadoop2.7/python/pyspark/cloudpickle.py\", line 730, in save_function_tuple\n",
      "    save(state)\n",
      "  File \"/home/luca/anaconda3/lib/python3.7/pickle.py\", line 504, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/home/luca/anaconda3/lib/python3.7/pickle.py\", line 859, in save_dict\n",
      "    self._batch_setitems(obj.items())\n",
      "  File \"/home/luca/anaconda3/lib/python3.7/pickle.py\", line 885, in _batch_setitems\n",
      "    save(v)\n",
      "  File \"/home/luca/anaconda3/lib/python3.7/pickle.py\", line 504, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/home/luca/anaconda3/lib/python3.7/pickle.py\", line 859, in save_dict\n",
      "    self._batch_setitems(obj.items())\n",
      "  File \"/home/luca/anaconda3/lib/python3.7/pickle.py\", line 885, in _batch_setitems\n",
      "    save(v)\n",
      "  File \"/home/luca/anaconda3/lib/python3.7/pickle.py\", line 549, in save\n",
      "    self.save_reduce(obj=obj, *rv)\n",
      "  File \"/home/luca/anaconda3/lib/python3.7/pickle.py\", line 662, in save_reduce\n",
      "    save(state)\n",
      "  File \"/home/luca/anaconda3/lib/python3.7/pickle.py\", line 504, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/home/luca/anaconda3/lib/python3.7/pickle.py\", line 859, in save_dict\n",
      "    self._batch_setitems(obj.items())\n",
      "  File \"/home/luca/anaconda3/lib/python3.7/pickle.py\", line 885, in _batch_setitems\n",
      "    save(v)\n",
      "  File \"/home/luca/anaconda3/lib/python3.7/pickle.py\", line 549, in save\n",
      "    self.save_reduce(obj=obj, *rv)\n",
      "  File \"/home/luca/anaconda3/lib/python3.7/pickle.py\", line 662, in save_reduce\n",
      "    save(state)\n",
      "  File \"/home/luca/anaconda3/lib/python3.7/pickle.py\", line 504, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/home/luca/anaconda3/lib/python3.7/pickle.py\", line 859, in save_dict\n",
      "    self._batch_setitems(obj.items())\n",
      "  File \"/home/luca/anaconda3/lib/python3.7/pickle.py\", line 885, in _batch_setitems\n",
      "    save(v)\n",
      "  File \"/home/luca/anaconda3/lib/python3.7/pickle.py\", line 549, in save\n",
      "    self.save_reduce(obj=obj, *rv)\n",
      "  File \"/home/luca/anaconda3/lib/python3.7/pickle.py\", line 662, in save_reduce\n",
      "    save(state)\n",
      "  File \"/home/luca/anaconda3/lib/python3.7/pickle.py\", line 504, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/home/luca/anaconda3/lib/python3.7/pickle.py\", line 859, in save_dict\n",
      "    self._batch_setitems(obj.items())\n",
      "  File \"/home/luca/anaconda3/lib/python3.7/pickle.py\", line 885, in _batch_setitems\n",
      "    save(v)\n",
      "  File \"/home/luca/anaconda3/lib/python3.7/pickle.py\", line 549, in save\n",
      "    self.save_reduce(obj=obj, *rv)\n",
      "  File \"/home/luca/anaconda3/lib/python3.7/pickle.py\", line 662, in save_reduce\n",
      "    save(state)\n",
      "  File \"/home/luca/anaconda3/lib/python3.7/pickle.py\", line 504, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/home/luca/anaconda3/lib/python3.7/pickle.py\", line 859, in save_dict\n",
      "    self._batch_setitems(obj.items())\n",
      "  File \"/home/luca/anaconda3/lib/python3.7/pickle.py\", line 885, in _batch_setitems\n",
      "    save(v)\n",
      "  File \"/home/luca/anaconda3/lib/python3.7/pickle.py\", line 549, in save\n",
      "    self.save_reduce(obj=obj, *rv)\n",
      "  File \"/home/luca/anaconda3/lib/python3.7/pickle.py\", line 662, in save_reduce\n",
      "    save(state)\n",
      "  File \"/home/luca/anaconda3/lib/python3.7/pickle.py\", line 504, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"/home/luca/anaconda3/lib/python3.7/pickle.py\", line 859, in save_dict\n",
      "    self._batch_setitems(obj.items())\n",
      "  File \"/home/luca/anaconda3/lib/python3.7/pickle.py\", line 885, in _batch_setitems\n",
      "    save(v)\n",
      "  File \"/home/luca/anaconda3/lib/python3.7/pickle.py\", line 524, in save\n",
      "    rv = reduce(self.proto)\n",
      "TypeError: can't pickle _thread.RLock objects\n"
     ]
    },
    {
     "ename": "PicklingError",
     "evalue": "Could not serialize object: TypeError: can't pickle _thread.RLock objects",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/Scrivania/BigData-project/spark-3.0.2-bin-hadoop2.7/python/pyspark/serializers.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcloudpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPickleError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Scrivania/BigData-project/spark-3.0.2-bin-hadoop2.7/python/pyspark/cloudpickle.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(obj, protocol)\u001b[0m\n\u001b[1;32m   1096\u001b[0m         \u001b[0mcp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCloudPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1097\u001b[0;31m         \u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1098\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Scrivania/BigData-project/spark-3.0.2-bin-hadoop2.7/python/pyspark/cloudpickle.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_framing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSTOP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave_tuple\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    788\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Scrivania/BigData-project/spark-3.0.2-bin-hadoop2.7/python/pyspark/cloudpickle.py\u001b[0m in \u001b[0;36msave_function\u001b[0;34m(self, obj, name)\u001b[0m\n\u001b[1;32m    500\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlookedup_by_name\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlookedup_by_name\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_function_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Scrivania/BigData-project/spark-3.0.2-bin-hadoop2.7/python/pyspark/cloudpickle.py\u001b[0m in \u001b[0;36msave_function_tuple\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m    729\u001b[0m             \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'kwdefaults'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__kwdefaults__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m         \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m         \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTUPLE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    884\u001b[0m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEMS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave_list\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_appends\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36m_batch_appends\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    842\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAPPENDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Scrivania/BigData-project/spark-3.0.2-bin-hadoop2.7/python/pyspark/cloudpickle.py\u001b[0m in \u001b[0;36msave_function\u001b[0;34m(self, obj, name)\u001b[0m\n\u001b[1;32m    500\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlookedup_by_name\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlookedup_by_name\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_function_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Scrivania/BigData-project/spark-3.0.2-bin-hadoop2.7/python/pyspark/cloudpickle.py\u001b[0m in \u001b[0;36msave_function_tuple\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m    729\u001b[0m             \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'kwdefaults'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__kwdefaults__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m         \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m         \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTUPLE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    884\u001b[0m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEMS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave_list\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_appends\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36m_batch_appends\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    845\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAPPEND\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Scrivania/BigData-project/spark-3.0.2-bin-hadoop2.7/python/pyspark/cloudpickle.py\u001b[0m in \u001b[0;36msave_function\u001b[0;34m(self, obj, name)\u001b[0m\n\u001b[1;32m    495\u001b[0m                 or themodule is None):\n\u001b[0;32m--> 496\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_function_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Scrivania/BigData-project/spark-3.0.2-bin-hadoop2.7/python/pyspark/cloudpickle.py\u001b[0m in \u001b[0;36msave_function_tuple\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m    729\u001b[0m             \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'kwdefaults'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__kwdefaults__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m         \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m         \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTUPLE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    884\u001b[0m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEMS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    884\u001b[0m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEMS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# Save the reduce() output and finally memoize the object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, obj)\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m             \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m             \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBUILD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    884\u001b[0m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEMS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# Save the reduce() output and finally memoize the object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, obj)\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m             \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m             \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBUILD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    884\u001b[0m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEMS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# Save the reduce() output and finally memoize the object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, obj)\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m             \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m             \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBUILD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    884\u001b[0m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEMS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# Save the reduce() output and finally memoize the object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, obj)\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m             \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m             \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBUILD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    884\u001b[0m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEMS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# Save the reduce() output and finally memoize the object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, obj)\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m             \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m             \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBUILD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    884\u001b[0m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEMS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m                 \u001b[0mrv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    525\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't pickle _thread.RLock objects",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-6392b32f52a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0mmap_film\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmovies_without_MrSmith\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatMap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmid_movieMrSmith\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;31m#movies_without_MrSmith.withColumn('rating', similarity(mid_movieMrSmith,movies_without_MrSmith.collect()[0][0])[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0mmap_film\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Scrivania/BigData-project/spark-3.0.2-bin-hadoop2.7/python/pyspark/rdd.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, num)\u001b[0m\n\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartsScanned\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartsScanned\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnumPartsToTry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotalParts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1446\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunJob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtakeUpToNumLeft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1448\u001b[0m             \u001b[0mitems\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Scrivania/BigData-project/spark-3.0.2-bin-hadoop2.7/python/pyspark/context.py\u001b[0m in \u001b[0;36mrunJob\u001b[0;34m(self, rdd, partitionFunc, partitions, allowLocal)\u001b[0m\n\u001b[1;32m   1118\u001b[0m         \u001b[0;31m# SparkContext#runJob.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m         \u001b[0mmappedRDD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartitionFunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1120\u001b[0;31m         \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunJob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmappedRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartitions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1121\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmappedRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Scrivania/BigData-project/spark-3.0.2-bin-hadoop2.7/python/pyspark/rdd.py\u001b[0m in \u001b[0;36m_jrdd\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2628\u001b[0m         wrapped_func = _wrap_function(self.ctx, self.func, self._prev_jrdd_deserializer,\n\u001b[0;32m-> 2629\u001b[0;31m                                       self._jrdd_deserializer, profiler)\n\u001b[0m\u001b[1;32m   2630\u001b[0m         python_rdd = self.ctx._jvm.PythonRDD(self._prev_jrdd.rdd(), wrapped_func,\n\u001b[1;32m   2631\u001b[0m                                              self.preservesPartitioning, self.is_barrier)\n",
      "\u001b[0;32m~/Scrivania/BigData-project/spark-3.0.2-bin-hadoop2.7/python/pyspark/rdd.py\u001b[0m in \u001b[0;36m_wrap_function\u001b[0;34m(sc, func, deserializer, serializer, profiler)\u001b[0m\n\u001b[1;32m   2515\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mserializer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"serializer should not be empty\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2516\u001b[0m     \u001b[0mcommand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofiler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeserializer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2517\u001b[0;31m     \u001b[0mpickled_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbroadcast_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincludes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_prepare_for_python_RDD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2518\u001b[0m     return sc._jvm.PythonFunction(bytearray(pickled_command), env, includes, sc.pythonExec,\n\u001b[1;32m   2519\u001b[0m                                   sc.pythonVer, broadcast_vars, sc._javaAccumulator)\n",
      "\u001b[0;32m~/Scrivania/BigData-project/spark-3.0.2-bin-hadoop2.7/python/pyspark/rdd.py\u001b[0m in \u001b[0;36m_prepare_for_python_RDD\u001b[0;34m(sc, command)\u001b[0m\n\u001b[1;32m   2501\u001b[0m     \u001b[0;31m# the serialized command will be compressed by broadcast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2502\u001b[0m     \u001b[0mser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCloudPickleSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2503\u001b[0;31m     \u001b[0mpickled_command\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2504\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickled_command\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetBroadcastThreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Default 1M\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2505\u001b[0m         \u001b[0;31m# The broadcast will have same life cycle as created PythonRDD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Scrivania/BigData-project/spark-3.0.2-bin-hadoop2.7/python/pyspark/serializers.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    476\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Could not serialize object: %s: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mprint_exec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPicklingError\u001b[0m: Could not serialize object: TypeError: can't pickle _thread.RLock objects"
     ]
    }
   ],
   "source": [
    "import time\n",
    "minYear = int(movies.select(min(movies.year)).collect()[0][0])\n",
    "maxYear = int(movies.select(max(movies.year)).collect()[0][0])\n",
    "maxRating = float(movies.filter(movies.rating != '\\\\N').select(max(movies.rating)).collect()[0][0])\n",
    "\n",
    "def get_mid(movie):\n",
    "    return movies.filter(movies.title == movie).select('mid').collect()[0][0]\n",
    "\n",
    "\n",
    "def similarity(mid_movie1, mid_movie2):\n",
    "    \n",
    "    get_num_actor = len(actors.filter(actors.mid == mid_movie1).select('name').collect())\n",
    "    get_num_tags = len(tags.filter(tags.mid == mid_movie1).select('tid').distinct().collect())\n",
    "    get_num_genres = len(genres.filter(genres.mid == mid_movie1).select('genre').distinct().collect())\n",
    "    \n",
    "    actorsMovie1 = actors.filter(actors.mid == mid_movie1).select('name')\n",
    "    actorsMovie2 = actors.filter(actors.mid == mid_movie2).select('name')\n",
    "    intersect_actor =  len(actorsMovie1.intersect(actorsMovie2).collect())/get_num_actor\n",
    "    \n",
    "    tagsMovie1 = tags.filter(tags.mid == mid_movie1).select('tid')\n",
    "    tagsMovie2 = tags.filter(tags.mid == mid_movie2).select('tid')\n",
    "    intersect_tag = len(tagsMovie1.intersect(tagsMovie2).collect())/get_num_tags\n",
    "    \n",
    "    genreMovie1 = genres.filter(genres.mid == mid_movie1).select('genre')\n",
    "    genreMovie2 = genres.filter(genres.mid == mid_movie2).select('genre')\n",
    "    intersect_genre =  len(genreMovie1.intersect(genreMovie2).collect())/get_num_genres\n",
    "    \n",
    "    year_movie1 = int(movies.filter(movies.mid == mid_movie1).select('year').collect()[0][0])\n",
    "    year_movie2 = int(movies.filter(movies.mid == mid_movie2).select('year').collect()[0][0])\n",
    "    difference = abs(year_movie1 - year_movie2)\n",
    "    age_gap =  1 - (difference/maxYear)\n",
    "    \n",
    "    \n",
    "    rating_movie1 = float(movies.filter(movies.mid == mid_movie1).select('rating').collect()[0][0])\n",
    "    rating_movie2 = float(movies.filter(movies.mid == mid_movie2).select('rating').collect()[0][0])\n",
    "    difference_gap = abs(rating_movie1 - rating_movie2) \n",
    "    rating_gap = 1 - (difference_gap/maxRating)\n",
    "    similarity = (intersect_actor+intersect_tag+intersect_genre + age_gap + rating_gap)/5\n",
    "    \n",
    "    myFloatRdd = sc.parallelize([similarity])\n",
    "    row = Row(\"similarity\") \n",
    "    result = myFloatRdd.map(row).toDF()\n",
    "\n",
    "    \n",
    "    return result.select('similarity')\n",
    "\n",
    "\n",
    "mid_movieMrSmith = get_mid('Mr. & Mrs. Smith')\n",
    "movies_without_MrSmith = movies.filter(movies.mid != mid_movieMrSmith).filter(movies.rating != '\\\\N').select('mid','rating')\n",
    "similarity_for_movies = []\n",
    "\n",
    "'''\n",
    "for mid in movies_without_MrSmith.collect():\n",
    "    similarity_for_movies.append((mid_movieMrSmith,mid[0], similarity(mid_movieMrSmith,mid[0])))\n",
    "\n",
    "print(similarity_for_movies)\n",
    "\n",
    "'''\n",
    "\n",
    "#map_film = movies_without_MrSmith.rdd.flatMap(lambda x: ((mid_movieMrSmith,x.mid), similarity(mid_movieMrSmith, x.collect()[0][0])))\n",
    "map_film = movies_without_MrSmith.rdd.flatMap(lambda x: ((mid_movieMrSmith,x.mid), lambda x: (len(actors.filter(actors.mid == x.mid).select('name').collect()[0][0]))))\n",
    "#movies_without_MrSmith.withColumn('rating', similarity(mid_movieMrSmith,movies_without_MrSmith.collect()[0][0])[0])\n",
    "map_film.take(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
